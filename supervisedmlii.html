<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Supervised machine learning II | Applied Geodata Science</title>
  <meta name="description" content="This course prepares you to benefit from the general data richness in environmental and geo-sciences." />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Supervised machine learning II | Applied Geodata Science" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This course prepares you to benefit from the general data richness in environmental and geo-sciences." />
  <meta name="github-repo" content="geco-bern/agsd" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Supervised machine learning II | Applied Geodata Science" />
  
  <meta name="twitter:description" content="This course prepares you to benefit from the general data richness in environmental and geo-sciences." />
  

<meta name="author" content="Benjamin Stocker, Koen Hufkens, Pepa ArÃ¡n, and Pascal Schneider" />


<meta name="date" content="2023-04-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="figures/apple-touch-icon.png" />
  <link rel="shortcut icon" href="figures/favicon.ico" type="image/x-icon" />
<link rel="prev" href="supervisedmli.html"/>
<link rel="next" href="randomforest.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied Geodata Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i>About this book</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#links"><i class="fa fa-check"></i>Links</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-cite-this-book"><i class="fa fa-check"></i>How to cite this book</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-course"><i class="fa fa-check"></i>About this course</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-goal"><i class="fa fa-check"></i>Course goal</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-objectives"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-contents"><i class="fa fa-check"></i>Course contents</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#what-is-applied-geodata-science"><i class="fa fa-check"></i>What is Applied Geodata Science?</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#the-data-science-workflow"><i class="fa fa-check"></i>The data science workflow</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#why-now"><i class="fa fa-check"></i>Why now?</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#a-new-modelling-paradigm"><i class="fa fa-check"></i>A new modelling paradigm</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#reading-and-link-collection"><i class="fa fa-check"></i>Reading and link collection</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="gettingstarted.html"><a href="gettingstarted.html"><i class="fa fa-check"></i><b>1</b> Getting started</a>
<ul>
<li class="chapter" data-level="1.1" data-path="gettingstarted.html"><a href="gettingstarted.html#learning-objectives-1"><i class="fa fa-check"></i><b>1.1</b> Learning objectives</a></li>
<li class="chapter" data-level="1.2" data-path="gettingstarted.html"><a href="gettingstarted.html#tutorial"><i class="fa fa-check"></i><b>1.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="gettingstarted.html"><a href="gettingstarted.html#working-with-r-and-rstudio"><i class="fa fa-check"></i><b>1.2.1</b> Working with R and RStudio</a></li>
<li class="chapter" data-level="1.2.2" data-path="gettingstarted.html"><a href="gettingstarted.html#r-objects"><i class="fa fa-check"></i><b>1.2.2</b> R objects</a></li>
<li class="chapter" data-level="1.2.3" data-path="gettingstarted.html"><a href="gettingstarted.html#r-environment"><i class="fa fa-check"></i><b>1.2.3</b> R environment</a></li>
<li class="chapter" data-level="1.2.4" data-path="gettingstarted.html"><a href="gettingstarted.html#libraries"><i class="fa fa-check"></i><b>1.2.4</b> Libraries</a></li>
<li class="chapter" data-level="1.2.5" data-path="gettingstarted.html"><a href="gettingstarted.html#r-scripts"><i class="fa fa-check"></i><b>1.2.5</b> R scripts</a></li>
<li class="chapter" data-level="1.2.6" data-path="gettingstarted.html"><a href="gettingstarted.html#rmarkdown"><i class="fa fa-check"></i><b>1.2.6</b> R Markdown</a></li>
<li class="chapter" data-level="1.2.7" data-path="gettingstarted.html"><a href="gettingstarted.html#wspmgmt"><i class="fa fa-check"></i><b>1.2.7</b> Workspace management</a></li>
<li class="chapter" data-level="1.2.8" data-path="gettingstarted.html"><a href="gettingstarted.html#setup"><i class="fa fa-check"></i><b>1.2.8</b> Setup</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="gettingstarted.html"><a href="gettingstarted.html#exercises"><i class="fa fa-check"></i><b>1.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#dimensions-of-a-circle"><i class="fa fa-check"></i>Dimensions of a circle</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#sequence-of-numbers"><i class="fa fa-check"></i>Sequence of numbers</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#gauss-sum"><i class="fa fa-check"></i>Gauss sum</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#magic-trick-algorithm"><i class="fa fa-check"></i>Magic trick algorithm</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#vectors-1"><i class="fa fa-check"></i>Vectors</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#data-frames-1"><i class="fa fa-check"></i>Data frames</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#workspace"><i class="fa fa-check"></i>Workspace</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="programmingprimers.html"><a href="programmingprimers.html"><i class="fa fa-check"></i><b>2</b> Programming primers</a>
<ul>
<li class="chapter" data-level="2.1" data-path="programmingprimers.html"><a href="programmingprimers.html#learning-objectives-2"><i class="fa fa-check"></i><b>2.1</b> Learning objectives</a></li>
<li class="chapter" data-level="2.2" data-path="programmingprimers.html"><a href="programmingprimers.html#tutorial-1"><i class="fa fa-check"></i><b>2.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="programmingprimers.html"><a href="programmingprimers.html#programming-basics"><i class="fa fa-check"></i><b>2.2.1</b> Programming basics</a></li>
<li class="chapter" data-level="2.2.2" data-path="programmingprimers.html"><a href="programmingprimers.html#style-your-code"><i class="fa fa-check"></i><b>2.2.2</b> Style your code</a></li>
<li class="chapter" data-level="2.2.3" data-path="programmingprimers.html"><a href="programmingprimers.html#findinghelp"><i class="fa fa-check"></i><b>2.2.3</b> Where to find help</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="programmingprimers.html"><a href="programmingprimers.html#exercises-1"><i class="fa fa-check"></i><b>2.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="programmingprimers.html"><a href="programmingprimers.html#gauss-variations"><i class="fa fa-check"></i>Gauss variations</a></li>
<li class="chapter" data-level="" data-path="programmingprimers.html"><a href="programmingprimers.html#nested-loops"><i class="fa fa-check"></i>Nested loops</a></li>
<li class="chapter" data-level="" data-path="programmingprimers.html"><a href="programmingprimers.html#interpolation"><i class="fa fa-check"></i>Interpolation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="datawrangling.html"><a href="datawrangling.html"><i class="fa fa-check"></i><b>3</b> Data wrangling</a>
<ul>
<li class="chapter" data-level="3.1" data-path="datawrangling.html"><a href="datawrangling.html#learning-objectives-3"><i class="fa fa-check"></i><b>3.1</b> Learning objectives</a></li>
<li class="chapter" data-level="3.2" data-path="datawrangling.html"><a href="datawrangling.html#tutorial-2"><i class="fa fa-check"></i><b>3.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="datawrangling.html"><a href="datawrangling.html#example-data"><i class="fa fa-check"></i><b>3.2.1</b> Example data</a></li>
<li class="chapter" data-level="3.2.2" data-path="datawrangling.html"><a href="datawrangling.html#tidyverse"><i class="fa fa-check"></i><b>3.2.2</b> Tidyverse</a></li>
<li class="chapter" data-level="3.2.3" data-path="datawrangling.html"><a href="datawrangling.html#reading-tabular-data"><i class="fa fa-check"></i><b>3.2.3</b> Reading tabular data</a></li>
<li class="chapter" data-level="3.2.4" data-path="datawrangling.html"><a href="datawrangling.html#variable-selection"><i class="fa fa-check"></i><b>3.2.4</b> Variable selection</a></li>
<li class="chapter" data-level="3.2.5" data-path="datawrangling.html"><a href="datawrangling.html#time-objects"><i class="fa fa-check"></i><b>3.2.5</b> Time objects</a></li>
<li class="chapter" data-level="3.2.6" data-path="datawrangling.html"><a href="datawrangling.html#variable-re--definition"><i class="fa fa-check"></i><b>3.2.6</b> Variable (re-) definition</a></li>
<li class="chapter" data-level="3.2.7" data-path="datawrangling.html"><a href="datawrangling.html#axes-of-variation"><i class="fa fa-check"></i><b>3.2.7</b> Axes of variation</a></li>
<li class="chapter" data-level="3.2.8" data-path="datawrangling.html"><a href="datawrangling.html#tidydata"><i class="fa fa-check"></i><b>3.2.8</b> Tidy data</a></li>
<li class="chapter" data-level="3.2.9" data-path="datawrangling.html"><a href="datawrangling.html#aggregating-data"><i class="fa fa-check"></i><b>3.2.9</b> Aggregating data</a></li>
<li class="chapter" data-level="3.2.10" data-path="datawrangling.html"><a href="datawrangling.html#data-cleaning"><i class="fa fa-check"></i><b>3.2.10</b> Data cleaning</a></li>
<li class="chapter" data-level="3.2.11" data-path="datawrangling.html"><a href="datawrangling.html#writing-data-to-csv"><i class="fa fa-check"></i><b>3.2.11</b> Writing data to CSV</a></li>
<li class="chapter" data-level="3.2.12" data-path="datawrangling.html"><a href="datawrangling.html#combining-relational-data"><i class="fa fa-check"></i><b>3.2.12</b> Combining relational data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="datawrangling.html"><a href="datawrangling.html#extramaterialwrangling"><i class="fa fa-check"></i><b>3.3</b> Extra material</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="datawrangling.html"><a href="datawrangling.html#functional-programming-i"><i class="fa fa-check"></i><b>3.3.1</b> Functional programming I</a></li>
<li class="chapter" data-level="3.3.2" data-path="datawrangling.html"><a href="datawrangling.html#strings"><i class="fa fa-check"></i><b>3.3.2</b> Strings</a></li>
<li class="chapter" data-level="3.3.3" data-path="datawrangling.html"><a href="datawrangling.html#functional-programming-ii"><i class="fa fa-check"></i><b>3.3.3</b> Functional programming II</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="datawrangling.html"><a href="datawrangling.html#exerciseswrangling"><i class="fa fa-check"></i><b>3.4</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="datawrangling.html"><a href="datawrangling.html#star-wars"><i class="fa fa-check"></i>Star wars</a></li>
<li class="chapter" data-level="" data-path="datawrangling.html"><a href="datawrangling.html#aggregating"><i class="fa fa-check"></i>Aggregating</a></li>
<li class="chapter" data-level="" data-path="datawrangling.html"><a href="datawrangling.html#patterns-in-data-quality"><i class="fa fa-check"></i>Patterns in data quality</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="datawrangling.html"><a href="datawrangling.html#report-exercise"><i class="fa fa-check"></i><b>3.5</b> Report Exercise</a>
<ul>
<li class="chapter" data-level="" data-path="datawrangling.html"><a href="datawrangling.html#cleaning-data-from-elevated-co_2-experiments"><i class="fa fa-check"></i>Cleaning data from elevated CO<span class="math inline">\(_2\)</span> experiments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="datavis.html"><a href="datavis.html"><i class="fa fa-check"></i><b>4</b> Data visualisation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="datavis.html"><a href="datavis.html#learning-objectives-4"><i class="fa fa-check"></i><b>4.1</b> Learning objectives</a></li>
<li class="chapter" data-level="4.2" data-path="datavis.html"><a href="datavis.html#tutorial-3"><i class="fa fa-check"></i><b>4.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="datavis.html"><a href="datavis.html#the-grammar-of-graphics"><i class="fa fa-check"></i><b>4.2.1</b> The grammar of graphics</a></li>
<li class="chapter" data-level="4.2.2" data-path="datavis.html"><a href="datavis.html#every-data-has-its-representation"><i class="fa fa-check"></i><b>4.2.2</b> Every data has its representation</a></li>
<li class="chapter" data-level="4.2.3" data-path="datavis.html"><a href="datavis.html#writing-to-file"><i class="fa fa-check"></i><b>4.2.3</b> Writing to file</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="datavis.html"><a href="datavis.html#exercises-2"><i class="fa fa-check"></i><b>4.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="datavis.html"><a href="datavis.html#spurious-data"><i class="fa fa-check"></i>Spurious data</a></li>
<li class="chapter" data-level="" data-path="datavis.html"><a href="datavis.html#identifying-outliers"><i class="fa fa-check"></i>Identifying Outliers</a></li>
<li class="chapter" data-level="" data-path="datavis.html"><a href="datavis.html#visualising-diurnal-and-seasonal-cycles-of-gpp"><i class="fa fa-check"></i>Visualising diurnal and seasonal cycles of GPP</a></li>
<li class="chapter" data-level="" data-path="datavis.html"><a href="datavis.html#trend-in-carbon-dioxide-concentrations"><i class="fa fa-check"></i>Trend in carbon dioxide concentrations</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="datavis.html"><a href="datavis.html#report-exercises"><i class="fa fa-check"></i><b>4.4</b> Report Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="datavis.html"><a href="datavis.html#telling-a-story-from-data"><i class="fa fa-check"></i>Telling a story from data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="datavariety.html"><a href="datavariety.html"><i class="fa fa-check"></i><b>5</b> Data variety</a>
<ul>
<li class="chapter" data-level="5.1" data-path="datavariety.html"><a href="datavariety.html#learning-objectives-5"><i class="fa fa-check"></i><b>5.1</b> Learning objectives</a></li>
<li class="chapter" data-level="5.2" data-path="datavariety.html"><a href="datavariety.html#tutorial-4"><i class="fa fa-check"></i><b>5.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="datavariety.html"><a href="datavariety.html#files-and-file-formats"><i class="fa fa-check"></i><b>5.2.1</b> Files and file formats</a></li>
<li class="chapter" data-level="5.2.2" data-path="datavariety.html"><a href="datavariety.html#meta-data"><i class="fa fa-check"></i><b>5.2.2</b> Meta-data</a></li>
<li class="chapter" data-level="5.2.3" data-path="datavariety.html"><a href="datavariety.html#spatial-data-representation"><i class="fa fa-check"></i><b>5.2.3</b> Spatial data representation</a></li>
<li class="chapter" data-level="5.2.4" data-path="datavariety.html"><a href="datavariety.html#online-data-sources"><i class="fa fa-check"></i><b>5.2.4</b> Online data sources</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="datavariety.html"><a href="datavariety.html#exercises-3"><i class="fa fa-check"></i><b>5.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="datavariety.html"><a href="datavariety.html#files-and-file-formats-1"><i class="fa fa-check"></i>Files and file formats</a></li>
<li class="chapter" data-level="" data-path="datavariety.html"><a href="datavariety.html#api-use"><i class="fa fa-check"></i>API use</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="openscience.html"><a href="openscience.html"><i class="fa fa-check"></i><b>6</b> Open science practices</a>
<ul>
<li class="chapter" data-level="6.1" data-path="openscience.html"><a href="openscience.html#learning-objectives-6"><i class="fa fa-check"></i><b>6.1</b> Learning objectives</a></li>
<li class="chapter" data-level="6.2" data-path="openscience.html"><a href="openscience.html#tutorial-5"><i class="fa fa-check"></i><b>6.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="openscience.html"><a href="openscience.html#project-structure"><i class="fa fa-check"></i><b>6.2.1</b> Project structure</a></li>
<li class="chapter" data-level="6.2.2" data-path="openscience.html"><a href="openscience.html#managing-workflows"><i class="fa fa-check"></i><b>6.2.2</b> Managing workflows</a></li>
<li class="chapter" data-level="6.2.3" data-path="openscience.html"><a href="openscience.html#capturing-your-session-state"><i class="fa fa-check"></i><b>6.2.3</b> Capturing your session state</a></li>
<li class="chapter" data-level="6.2.4" data-path="openscience.html"><a href="openscience.html#capturing-a-system-state"><i class="fa fa-check"></i><b>6.2.4</b> Capturing a system state</a></li>
<li class="chapter" data-level="6.2.5" data-path="openscience.html"><a href="openscience.html#readable-reporting-using-rmarkdown"><i class="fa fa-check"></i><b>6.2.5</b> Readable reporting using Rmarkdown</a></li>
<li class="chapter" data-level="6.2.6" data-path="openscience.html"><a href="openscience.html#project-structure-1"><i class="fa fa-check"></i><b>6.2.6</b> Project structure</a></li>
<li class="chapter" data-level="6.2.7" data-path="openscience.html"><a href="openscience.html#data-retention"><i class="fa fa-check"></i><b>6.2.7</b> Data retention</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="openscience.html"><a href="openscience.html#exercises-4"><i class="fa fa-check"></i><b>6.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="openscience.html"><a href="openscience.html#external-data"><i class="fa fa-check"></i>External data</a></li>
<li class="chapter" data-level="" data-path="openscience.html"><a href="openscience.html#a-new-project"><i class="fa fa-check"></i>A new project</a></li>
<li class="chapter" data-level="" data-path="openscience.html"><a href="openscience.html#tracking-the-state-of-your-project"><i class="fa fa-check"></i>Tracking the state of your project</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="codemgmt.html"><a href="codemgmt.html"><i class="fa fa-check"></i><b>7</b> Code management</a>
<ul>
<li class="chapter" data-level="7.1" data-path="codemgmt.html"><a href="codemgmt.html#learning-objectives-7"><i class="fa fa-check"></i><b>7.1</b> Learning objectives</a></li>
<li class="chapter" data-level="7.2" data-path="codemgmt.html"><a href="codemgmt.html#tutorial-6"><i class="fa fa-check"></i><b>7.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="codemgmt.html"><a href="codemgmt.html#gitworkflow"><i class="fa fa-check"></i><b>7.2.1</b> Git and local version control</a></li>
<li class="chapter" data-level="7.2.2" data-path="codemgmt.html"><a href="codemgmt.html#remote-version-control"><i class="fa fa-check"></i><b>7.2.2</b> Remote version control</a></li>
<li class="chapter" data-level="7.2.3" data-path="codemgmt.html"><a href="codemgmt.html#location-based-code-management---github-templates"><i class="fa fa-check"></i><b>7.2.3</b> Location based code management - github templates</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="codemgmt.html"><a href="codemgmt.html#exercises-5"><i class="fa fa-check"></i><b>7.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="codemgmt.html"><a href="codemgmt.html#location-based-code-management"><i class="fa fa-check"></i>Location based code management</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="codemgmt.html"><a href="codemgmt.html#report-exercises-1"><i class="fa fa-check"></i><b>7.4</b> Report Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="codemgmt.html"><a href="codemgmt.html#collaborative-work-on-github"><i class="fa fa-check"></i>Collaborative Work on Github</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regressionclassification.html"><a href="regressionclassification.html"><i class="fa fa-check"></i><b>8</b> Regression and classification</a>
<ul>
<li class="chapter" data-level="8.1" data-path="regressionclassification.html"><a href="regressionclassification.html#learning-objectives-8"><i class="fa fa-check"></i><b>8.1</b> Learning objectives</a></li>
<li class="chapter" data-level="8.2" data-path="regressionclassification.html"><a href="regressionclassification.html#tutorial-7"><i class="fa fa-check"></i><b>8.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="regressionclassification.html"><a href="regressionclassification.html#types-of-models"><i class="fa fa-check"></i><b>8.2.1</b> Types of models</a></li>
<li class="chapter" data-level="8.2.2" data-path="regressionclassification.html"><a href="regressionclassification.html#regression"><i class="fa fa-check"></i><b>8.2.2</b> Regression</a></li>
<li class="chapter" data-level="8.2.3" data-path="regressionclassification.html"><a href="regressionclassification.html#model-selection"><i class="fa fa-check"></i><b>8.2.3</b> Model selection</a></li>
<li class="chapter" data-level="8.2.4" data-path="regressionclassification.html"><a href="regressionclassification.html#outlier-detection"><i class="fa fa-check"></i><b>8.2.4</b> Outlier detection</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="regressionclassification.html"><a href="regressionclassification.html#extra-material"><i class="fa fa-check"></i><b>8.3</b> Extra material</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="regressionclassification.html"><a href="regressionclassification.html#classification"><i class="fa fa-check"></i><b>8.3.1</b> Classification</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="regressionclassification.html"><a href="regressionclassification.html#exercises-6"><i class="fa fa-check"></i><b>8.4</b> Exercises</a></li>
<li class="chapter" data-level="8.5" data-path="regressionclassification.html"><a href="regressionclassification.html#report-exercise-1"><i class="fa fa-check"></i><b>8.5</b> Report Exercise</a>
<ul>
<li class="chapter" data-level="" data-path="regressionclassification.html"><a href="regressionclassification.html#deliverables-for-the-report-1"><i class="fa fa-check"></i>Deliverables for the report</a></li>
<li class="chapter" data-level="" data-path="regressionclassification.html"><a href="regressionclassification.html#guide-for-your-implementation"><i class="fa fa-check"></i>Guide for your implementation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="supervisedmli.html"><a href="supervisedmli.html"><i class="fa fa-check"></i><b>9</b> Supervised machine learning I</a>
<ul>
<li class="chapter" data-level="9.1" data-path="supervisedmli.html"><a href="supervisedmli.html#learning-objectives-9"><i class="fa fa-check"></i><b>9.1</b> Learning objectives</a></li>
<li class="chapter" data-level="9.2" data-path="supervisedmli.html"><a href="supervisedmli.html#tutorial-8"><i class="fa fa-check"></i><b>9.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="supervisedmli.html"><a href="supervisedmli.html#what-is-supervised-machine-learning"><i class="fa fa-check"></i><b>9.2.1</b> What is supervised machine learning?</a></li>
<li class="chapter" data-level="9.2.2" data-path="supervisedmli.html"><a href="supervisedmli.html#overfitting"><i class="fa fa-check"></i><b>9.2.2</b> Overfitting</a></li>
<li class="chapter" data-level="9.2.3" data-path="supervisedmli.html"><a href="supervisedmli.html#data-and-the-modelling-challenge"><i class="fa fa-check"></i><b>9.2.3</b> Data and the modelling challenge</a></li>
<li class="chapter" data-level="9.2.4" data-path="supervisedmli.html"><a href="supervisedmli.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>9.2.4</b> K-nearest neighbours</a></li>
<li class="chapter" data-level="9.2.5" data-path="supervisedmli.html"><a href="supervisedmli.html#model-formulation"><i class="fa fa-check"></i><b>9.2.5</b> Model formulation</a></li>
<li class="chapter" data-level="9.2.6" data-path="supervisedmli.html"><a href="supervisedmli.html#data-splitting"><i class="fa fa-check"></i><b>9.2.6</b> Data splitting</a></li>
<li class="chapter" data-level="9.2.7" data-path="supervisedmli.html"><a href="supervisedmli.html#preprocessing"><i class="fa fa-check"></i><b>9.2.7</b> Pre-processing</a></li>
<li class="chapter" data-level="9.2.8" data-path="supervisedmli.html"><a href="supervisedmli.html#putting-it-all-together-half-way"><i class="fa fa-check"></i><b>9.2.8</b> Putting it all together (half-way)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="supervisedmli.html"><a href="supervisedmli.html#exercises-7"><i class="fa fa-check"></i><b>9.3</b> Exercises</a></li>
<li class="chapter" data-level="9.4" data-path="supervisedmli.html"><a href="supervisedmli.html#report-exercises-2"><i class="fa fa-check"></i><b>9.4</b> Report Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="supervisedmli.html"><a href="supervisedmli.html#comparison-of-the-linear-regression-and-knn-models"><i class="fa fa-check"></i>Comparison of the linear regression and KNN models</a></li>
<li class="chapter" data-level="" data-path="supervisedmli.html"><a href="supervisedmli.html#the-role-of-k"><i class="fa fa-check"></i>The role of k</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="supervisedmlii.html"><a href="supervisedmlii.html"><i class="fa fa-check"></i><b>10</b> Supervised machine learning II</a>
<ul>
<li class="chapter" data-level="10.1" data-path="supervisedmlii.html"><a href="supervisedmlii.html#learning-objectives-10"><i class="fa fa-check"></i><b>10.1</b> Learning objectives</a></li>
<li class="chapter" data-level="10.2" data-path="supervisedmlii.html"><a href="supervisedmlii.html#tutorial-9"><i class="fa fa-check"></i><b>10.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="supervisedmlii.html"><a href="supervisedmlii.html#data-and-the-modelling-challenge-1"><i class="fa fa-check"></i><b>10.2.1</b> Data and the modelling challenge</a></li>
<li class="chapter" data-level="10.2.2" data-path="supervisedmlii.html"><a href="supervisedmlii.html#training"><i class="fa fa-check"></i><b>10.2.2</b> Loss function</a></li>
<li class="chapter" data-level="10.2.3" data-path="supervisedmlii.html"><a href="supervisedmlii.html#hyperparameters"><i class="fa fa-check"></i><b>10.2.3</b> Hyperparameters</a></li>
<li class="chapter" data-level="10.2.4" data-path="supervisedmlii.html"><a href="supervisedmlii.html#resampling"><i class="fa fa-check"></i><b>10.2.4</b> Resampling</a></li>
<li class="chapter" data-level="10.2.5" data-path="supervisedmlii.html"><a href="supervisedmlii.html#validation-versus-testing-data"><i class="fa fa-check"></i><b>10.2.5</b> Validation versus testing data</a></li>
<li class="chapter" data-level="10.2.6" data-path="supervisedmlii.html"><a href="supervisedmlii.html#modeling-with-structured-data"><i class="fa fa-check"></i><b>10.2.6</b> Modeling with structured data</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="supervisedmlii.html"><a href="supervisedmlii.html#exercises-8"><i class="fa fa-check"></i><b>10.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="supervisedmlii.html"><a href="supervisedmlii.html#cross-validation-by-hand"><i class="fa fa-check"></i>Cross-validation by hand</a></li>
<li class="chapter" data-level="10.3.1" data-path="supervisedmlii.html"><a href="supervisedmlii.html#cross-validation-vs.-test-error"><i class="fa fa-check"></i><b>10.3.1</b> Cross-validation vs.Â test error</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="supervisedmlii.html"><a href="supervisedmlii.html#report-exercises-3"><i class="fa fa-check"></i><b>10.4</b> Report Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="randomforest.html"><a href="randomforest.html"><i class="fa fa-check"></i><b>11</b> Random Forest</a>
<ul>
<li class="chapter" data-level="11.1" data-path="randomforest.html"><a href="randomforest.html#learning-objectives-11"><i class="fa fa-check"></i><b>11.1</b> Learning objectives</a></li>
<li class="chapter" data-level="11.2" data-path="randomforest.html"><a href="randomforest.html#tutorial-10"><i class="fa fa-check"></i><b>11.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="randomforest.html"><a href="randomforest.html#decision-trees"><i class="fa fa-check"></i><b>11.2.1</b> Decision trees</a></li>
<li class="chapter" data-level="11.2.2" data-path="randomforest.html"><a href="randomforest.html#bagging"><i class="fa fa-check"></i><b>11.2.2</b> Bagging</a></li>
<li class="chapter" data-level="11.2.3" data-path="randomforest.html"><a href="randomforest.html#from-trees-to-a-forest"><i class="fa fa-check"></i><b>11.2.3</b> From trees to a forest</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="randomforest.html"><a href="randomforest.html#exercises-9"><i class="fa fa-check"></i><b>11.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="randomforest.html"><a href="randomforest.html#fitting-a-random-forest"><i class="fa fa-check"></i>Fitting a Random Forest</a></li>
<li class="chapter" data-level="" data-path="randomforest.html"><a href="randomforest.html#hyperparameter-tuning"><i class="fa fa-check"></i>Hyperparameter tuning</a></li>
<li class="chapter" data-level="" data-path="randomforest.html"><a href="randomforest.html#model-performance"><i class="fa fa-check"></i>Model performance</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="solutions.html"><a href="solutions.html"><i class="fa fa-check"></i><b>A</b> Solutions</a>
<ul>
<li class="chapter" data-level="A.1" data-path="solutions.html"><a href="solutions.html#getting-started"><i class="fa fa-check"></i><b>A.1</b> Getting Started</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#dimensions-of-a-circle-1"><i class="fa fa-check"></i>Dimensions of a circle</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#sequence-of-numbers-1"><i class="fa fa-check"></i>Sequence of numbers</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#gauss-sum-1"><i class="fa fa-check"></i>Gauss sum</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#magic-trick-algorithm-1"><i class="fa fa-check"></i>Magic trick algorithm</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#vectors-2"><i class="fa fa-check"></i>Vectors</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#data-frames-2"><i class="fa fa-check"></i>Data frames</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#workspace-1"><i class="fa fa-check"></i>Workspace</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="solutions.html"><a href="solutions.html#programming-primers"><i class="fa fa-check"></i><b>A.2</b> Programming primers</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#gauss-variations-1"><i class="fa fa-check"></i>Gauss variations</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#nested-loops-1"><i class="fa fa-check"></i>Nested loops</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#interpolation-1"><i class="fa fa-check"></i>Interpolation</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="solutions.html"><a href="solutions.html#data-wrangling"><i class="fa fa-check"></i><b>A.3</b> Data wrangling</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#star-wars-1"><i class="fa fa-check"></i>Star wars</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#aggregating-1"><i class="fa fa-check"></i>Aggregating</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#patterns-in-data-quality-1"><i class="fa fa-check"></i>Patterns in data quality</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="solutions.html"><a href="solutions.html#data-visualisation"><i class="fa fa-check"></i><b>A.4</b> Data Visualisation</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#spurious-data-1"><i class="fa fa-check"></i>Spurious data</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#identifying-outliers-1"><i class="fa fa-check"></i>Identifying Outliers</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#visualising-diurnal-and-seasonal-cycles-of-gpp-1"><i class="fa fa-check"></i>Visualising diurnal and seasonal cycles of GPP</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#trend-in-carbon-dioxide-concentrations-1"><i class="fa fa-check"></i>Trend in carbon dioxide concentrations</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="solutions.html"><a href="solutions.html#data-variety"><i class="fa fa-check"></i><b>A.5</b> Data Variety</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#files-and-file-formats-2"><i class="fa fa-check"></i>Files and file formats</a></li>
<li class="chapter" data-level="A.5.1" data-path="solutions.html"><a href="solutions.html#api-use-1"><i class="fa fa-check"></i><b>A.5.1</b> API Use</a></li>
</ul></li>
<li class="chapter" data-level="A.6" data-path="solutions.html"><a href="solutions.html#open-science"><i class="fa fa-check"></i><b>A.6</b> Open Science</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#external-data-1"><i class="fa fa-check"></i>External data</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#a-new-project-1"><i class="fa fa-check"></i>A new project</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#tracking-the-state-of-your-project-1"><i class="fa fa-check"></i>Tracking the state of your project</a></li>
</ul></li>
<li class="chapter" data-level="A.7" data-path="solutions.html"><a href="solutions.html#code-management"><i class="fa fa-check"></i><b>A.7</b> Code Management</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#location-based-code-management-1"><i class="fa fa-check"></i>Location based code management</a></li>
</ul></li>
<li class="chapter" data-level="A.8" data-path="solutions.html"><a href="solutions.html#regression-and-classification"><i class="fa fa-check"></i><b>A.8</b> Regression and Classification</a></li>
<li class="chapter" data-level="A.9" data-path="solutions.html"><a href="solutions.html#supervised-ml-i"><i class="fa fa-check"></i><b>A.9</b> Supervised ML I</a></li>
<li class="chapter" data-level="A.10" data-path="solutions.html"><a href="solutions.html#supervised-ml-ii"><i class="fa fa-check"></i><b>A.10</b> Supervised ML II</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#cross-validation-by-hand-1"><i class="fa fa-check"></i>Cross-validation by hand</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#cross-validation-vs.-test-error-1"><i class="fa fa-check"></i>Cross-validation vs.Â test error</a></li>
</ul></li>
<li class="chapter" data-level="A.11" data-path="solutions.html"><a href="solutions.html#random-forest"><i class="fa fa-check"></i><b>A.11</b> Random Forest</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#fitting-a-random-forest-1"><i class="fa fa-check"></i>Fitting a Random Forest</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#hyperparameter-tuning-1"><i class="fa fa-check"></i>Hyperparameter tuning</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#model-performance-1"><i class="fa fa-check"></i>Model performance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>B</b> References</a>
<ul>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html#system-information-and-package-list"><i class="fa fa-check"></i>System information and package list</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Geodata Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="supervisedmlii" class="section level1 hasAnchor" number="10">
<h1><span class="header-section-number">Chapter 10</span> Supervised machine learning II<a href="supervisedmlii.html#supervisedmlii" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><strong>Chapter lead author: Benjamin Stocker</strong></p>
<div id="learning-objectives-10" class="section level2 hasAnchor" number="10.1">
<h2><span class="header-section-number">10.1</span> Learning objectives<a href="supervisedmlii.html#learning-objectives-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the Chapter <a href="supervisedmli.html#supervisedmli">9</a>, you learned how the data are pre-processed, the model fitted, and how the modelâs generasbility to unseen data is tested. In the exercises of Chapter <a href="supervisedmli.html#supervisedmli">9</a>, you learned how the bias-variance trade-off of a model, a KNN, can be controlled and that the choice of model complexity has different implications of the modelâs performance on the training and the test sets. A âgoodâ model generalises well. That is, it performs well on unseen data.</p>
<p>In this chapter, you will learn more about the process of model training, the concept of the <em>loss</em>, and how we can chose the right level of model complexity for optimal model generalisability as part of the model training step. This completes your set of skills for your first implementations a supervised machine learning workflow.</p>
</div>
<div id="tutorial-9" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> Tutorial<a href="supervisedmlii.html#tutorial-9" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-and-the-modelling-challenge-1" class="section level3 hasAnchor" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> Data and the modelling challenge<a href="supervisedmlii.html#data-and-the-modelling-challenge-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Weâre using the same data and address the same modelling challenge as in Chapter <a href="supervisedmli.html#supervisedmli">9</a>. Letâs load the data, wrangle a bit, specify the same model formulation, and the same pre-processing steps as in the previous Chapter <a href="supervisedmli.html#supervisedmli">9</a>.</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="supervisedmlii.html#cb386-1" aria-hidden="true" tabindex="-1"></a>daily_fluxes <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_csv</span>(<span class="st">&quot;./data/FLX_CH-Dav_FLUXNET2015_FULLSET_DD_1997-2014_1-3.csv&quot;</span>) <span class="sc">|&gt;</span>  </span>
<span id="cb386-2"><a href="supervisedmlii.html#cb386-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb386-3"><a href="supervisedmlii.html#cb386-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># select only the variables we are interested in</span></span>
<span id="cb386-4"><a href="supervisedmlii.html#cb386-4" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(TIMESTAMP,</span>
<span id="cb386-5"><a href="supervisedmlii.html#cb386-5" aria-hidden="true" tabindex="-1"></a>                GPP_NT_VUT_REF,    <span class="co"># the target</span></span>
<span id="cb386-6"><a href="supervisedmlii.html#cb386-6" aria-hidden="true" tabindex="-1"></a>                <span class="fu">ends_with</span>(<span class="st">&quot;_QC&quot;</span>),  <span class="co"># quality control info</span></span>
<span id="cb386-7"><a href="supervisedmlii.html#cb386-7" aria-hidden="true" tabindex="-1"></a>                <span class="fu">ends_with</span>(<span class="st">&quot;_F&quot;</span>),   <span class="co"># includes all all meteorological covariates</span></span>
<span id="cb386-8"><a href="supervisedmlii.html#cb386-8" aria-hidden="true" tabindex="-1"></a>                <span class="sc">-</span><span class="fu">contains</span>(<span class="st">&quot;JSB&quot;</span>)   <span class="co"># weird useless variable</span></span>
<span id="cb386-9"><a href="supervisedmlii.html#cb386-9" aria-hidden="true" tabindex="-1"></a>                ) <span class="sc">|&gt;</span></span>
<span id="cb386-10"><a href="supervisedmlii.html#cb386-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb386-11"><a href="supervisedmlii.html#cb386-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># convert to a nice date object</span></span>
<span id="cb386-12"><a href="supervisedmlii.html#cb386-12" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">TIMESTAMP =</span> <span class="fu">ymd</span>(TIMESTAMP)) <span class="sc">|&gt;</span></span>
<span id="cb386-13"><a href="supervisedmlii.html#cb386-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb386-14"><a href="supervisedmlii.html#cb386-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># set all -9999 to NA</span></span>
<span id="cb386-15"><a href="supervisedmlii.html#cb386-15" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">na_if</span>(<span class="sc">-</span><span class="dv">9999</span>) <span class="sc">|&gt;</span></span>
<span id="cb386-16"><a href="supervisedmlii.html#cb386-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb386-17"><a href="supervisedmlii.html#cb386-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># retain only data based on &gt;=80% good-quality measurements</span></span>
<span id="cb386-18"><a href="supervisedmlii.html#cb386-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># overwrite bad data with NA (not dropping rows)</span></span>
<span id="cb386-19"><a href="supervisedmlii.html#cb386-19" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">GPP_NT_VUT_REF =</span> <span class="fu">ifelse</span>(NEE_VUT_REF_QC <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, GPP_NT_VUT_REF),</span>
<span id="cb386-20"><a href="supervisedmlii.html#cb386-20" aria-hidden="true" tabindex="-1"></a>                <span class="at">TA_F           =</span> <span class="fu">ifelse</span>(TA_F_QC        <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, TA_F),</span>
<span id="cb386-21"><a href="supervisedmlii.html#cb386-21" aria-hidden="true" tabindex="-1"></a>                <span class="at">SW_IN_F        =</span> <span class="fu">ifelse</span>(SW_IN_F_QC     <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, SW_IN_F),</span>
<span id="cb386-22"><a href="supervisedmlii.html#cb386-22" aria-hidden="true" tabindex="-1"></a>                <span class="at">LW_IN_F        =</span> <span class="fu">ifelse</span>(LW_IN_F_QC     <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, LW_IN_F),</span>
<span id="cb386-23"><a href="supervisedmlii.html#cb386-23" aria-hidden="true" tabindex="-1"></a>                <span class="at">VPD_F          =</span> <span class="fu">ifelse</span>(VPD_F_QC       <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, VPD_F),</span>
<span id="cb386-24"><a href="supervisedmlii.html#cb386-24" aria-hidden="true" tabindex="-1"></a>                <span class="at">PA_F           =</span> <span class="fu">ifelse</span>(PA_F_QC        <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, PA_F),</span>
<span id="cb386-25"><a href="supervisedmlii.html#cb386-25" aria-hidden="true" tabindex="-1"></a>                <span class="at">P_F            =</span> <span class="fu">ifelse</span>(P_F_QC         <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, P_F),</span>
<span id="cb386-26"><a href="supervisedmlii.html#cb386-26" aria-hidden="true" tabindex="-1"></a>                <span class="at">WS_F           =</span> <span class="fu">ifelse</span>(WS_F_QC        <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, WS_F)) <span class="sc">|&gt;</span> </span>
<span id="cb386-27"><a href="supervisedmlii.html#cb386-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb386-28"><a href="supervisedmlii.html#cb386-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># drop QC variables (no longer needed)</span></span>
<span id="cb386-29"><a href="supervisedmlii.html#cb386-29" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span><span class="fu">ends_with</span>(<span class="st">&quot;_QC&quot;</span>))</span>
<span id="cb386-30"><a href="supervisedmlii.html#cb386-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb386-31"><a href="supervisedmlii.html#cb386-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Data splitting</span></span>
<span id="cb386-32"><a href="supervisedmlii.html#cb386-32" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># for reproducibility</span></span>
<span id="cb386-33"><a href="supervisedmlii.html#cb386-33" aria-hidden="true" tabindex="-1"></a>split <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">initial_split</span>(daily_fluxes, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> <span class="st">&quot;VPD_F&quot;</span>)</span>
<span id="cb386-34"><a href="supervisedmlii.html#cb386-34" aria-hidden="true" tabindex="-1"></a>daily_fluxes_train <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">training</span>(split)</span>
<span id="cb386-35"><a href="supervisedmlii.html#cb386-35" aria-hidden="true" tabindex="-1"></a>daily_fluxes_test <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">testing</span>(split)</span>
<span id="cb386-36"><a href="supervisedmlii.html#cb386-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb386-37"><a href="supervisedmlii.html#cb386-37" aria-hidden="true" tabindex="-1"></a><span class="co"># The same model formulation is in the previous chapter</span></span>
<span id="cb386-38"><a href="supervisedmlii.html#cb386-38" aria-hidden="true" tabindex="-1"></a>pp <span class="ot">&lt;-</span> recipes<span class="sc">::</span><span class="fu">recipe</span>(GPP_NT_VUT_REF <span class="sc">~</span> SW_IN_F <span class="sc">+</span> VPD_F <span class="sc">+</span> TA_F, </span>
<span id="cb386-39"><a href="supervisedmlii.html#cb386-39" aria-hidden="true" tabindex="-1"></a>                      <span class="at">data =</span> daily_fluxes_train) <span class="sc">|&gt;</span> </span>
<span id="cb386-40"><a href="supervisedmlii.html#cb386-40" aria-hidden="true" tabindex="-1"></a>  recipes<span class="sc">::</span><span class="fu">step_center</span>(<span class="fu">all_numeric</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>()) <span class="sc">|&gt;</span></span>
<span id="cb386-41"><a href="supervisedmlii.html#cb386-41" aria-hidden="true" tabindex="-1"></a>  recipes<span class="sc">::</span><span class="fu">step_scale</span>(<span class="fu">all_numeric</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>())</span></code></pre></div>
<blockquote>
<p>To reproduce this code chunk, you can download the file <code>FLX_CH-Dav_FLUXNET2015_FULLSET_DD_1997-2014_1-3.csv</code> from <a href="https://raw.githubusercontent.com/geco-bern/agds/main/data/FLX_CH-Dav_FLUXNET2015_FULLSET_DD_1997-2014_1-3.csv">here</a> and read it from the local path where the file is stored on your machine. All data files used in this tutorials are stored <a href="https://github.com/geco-bern/agds/tree/main/data">here</a>.</p>
</blockquote>
</div>
<div id="training" class="section level3 hasAnchor" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> Loss function<a href="supervisedmlii.html#training" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Model training in supervised machine learning is guided by the match (or mismatch) between the predicted and observed target variable(s), that is, between <span class="math inline">\(\hat{Y}\)</span> and <span class="math inline">\(Y\)</span>. The <em>loss</em> function quantifies this mismatch (<span class="math inline">\(L(\hat{Y}, Y)\)</span>), and the algorithm (âoptimiserâ in Fig. 10.1 of Chapter <a href="supervisedmli.html#supervisedmli">9</a>) takes care of progressively reducing the loss during model training.</p>
<p>Letâs say the machine learning model contains two parameters and predictions can be considered a function of the two (<span class="math inline">\(\hat{Y}(w_1, w_2)\)</span>). <span class="math inline">\(Y\)</span> is actually constant. Thus, the loss function is effectively a function <span class="math inline">\(L(w_1, w_2)\)</span>. Therefore, we can consider the model training as a search of the parameter space to find the minimum of the loss. The parameter space spanned by all possible combinations of <span class="math inline">\((w_1, w_2)\)</span>. Common loss functions are the root mean square error (RMSE), or the mean square error (MSE), or the mean absolute error (MAE). Loss minimization is a general feature of ML model training.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lossfunction"></span>
<img src="figures/loss_plane.png" alt="Visualization of a loss function."  />
<p class="caption">
Figure 10.1: Visualization of a loss function.
</p>
</div>
<p>Model training is implemented in R for different machine learning algorithms in different packages. Some algorithms are even implemented by multiple packages. As described in Chapter @ref(#supervisedmli), the {caret} package provides âwrappersâ that handle a large selection of different machine learning model implementations in different packages with a unified interface (see <a href="https://topepo.github.io/caret/available-models.html">here</a> for an overview of available models). The {caret} function <code>train()</code> is the center piece also in terms of specifying the loss function as the argument <code>metric</code>. It defaults to the RMSE for regression models and the accuracy for classification.</p>
</div>
<div id="hyperparameters" class="section level3 hasAnchor" number="10.2.3">
<h3><span class="header-section-number">10.2.3</span> Hyperparameters<a href="supervisedmlii.html#hyperparameters" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Practically all machine learning algorithms have some âknobsâ to turn for controlling a modelâs complexity and other features of the model training. The optimal choice of these âknobsâ is to be found for efficient model performance. Such âknobsâ are the <em>hyperparameters</em>. Each algorithm comes with its own, specific hyperparameters.</p>
<p>For KNN, <code>k</code> is the (only) hyperparameter. It specifies the number of neighbours to consider for determining distances. There is always an optimum <span class="math inline">\(k\)</span>. Obviously, if <span class="math inline">\(k = n\)</span>, we consider all observations as neighbours and each prediction is simply the mean of all observed target values <span class="math inline">\(Y\)</span>, irrespective of the predictor values. This cannot be optimal and such a model is likely underfit. On the other extreme, with <span class="math inline">\(k = 1\)</span>, the model will be strongly affected by the noise in the single nearest neighbour and its generalisability will suffer. This should be reflected in a poor performance on the validation data.</p>
<p>Hyperparameters usually have to be âtunedâ. The optimal setting depends on the data and can therefore not be known <em>a priori</em>. Below is a visualisation of the loss (MAE) on the training and on the test set for different choices of <span class="math inline">\(k\)</span>.</p>
<!-- >>> CHECK FOR REDUCING COMPUTATIONAL COST TO RENDER BOOK ONLINE <<< -->
<!-- SAVE DATA WHEN RUNNING LOCALLY BY SETTING EVAL = TRUE, PUSH ONLY WITH EVAL = FALSE -->
<!-- >>> END OF CHECK <<< -->
<p><img src="_main_files/figure-html/unnamed-chunk-207-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>This illustrates that the model performance on the training set keeps improving as the model variance (as opposed to bias) increases - here as we go towards smaller <span class="math inline">\(k\)</span>. However, what counts for measuring out-of-sample model performance is the evaluation on the test set, which deteriorates with increasing model variance beyond a certain point.</p>
<p>Although decisive for the generalisability of the model, we cannot evaluate its performance on the test set during model training. We have set that data aside and must leave it untouched to have a basis for evaluating the model performance on unseen data after training. What can we do to determine the optimal hyperparameter choice during model training, estimating its performance on the test set?</p>
</div>
<div id="resampling" class="section level3 hasAnchor" number="10.2.4">
<h3><span class="header-section-number">10.2.4</span> Resampling<a href="supervisedmlii.html#resampling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The solution is to split the training data again - now into a training and a <em>validation</em> set. Using the validation set, we can âmimickâ out-of-sample predictions during training by determining the loss on the validation set and use that for guiding the model training. However, depending on the volume of data we have access to, evaluation metrics determined on the validation set may not be robust. Results may vary depending on the split into training and validation data. This makes it challenging for reliably estimating out-of-sample performance.</p>
<p>A solution for this problem is to <em>resample</em> the training data into a number training-validation splits, yielding several pairs of training and <em>validation</em> data. Model training is then guided by minimising the average loss determined on the different resamples. Having multiple resamples (multiple <em>folds</em> of training-validation splits) avoids the loss minimization from being misguided by random peculiarities in the training and/or validation data.</p>
<p>Whether or not a resampling is applied, depends on the data volume and computational costs of the model training which increase linearly with the number of resamples. For models that take days-weeks to train, resampling is not a realistic option. However, for many machine learning applications in Geography and Environmental Sciences, models are much less costly and resampling is viable and desirable approach to model training.</p>
<p>The most important methods of resampling are <strong>bootstrapping</strong> (not explained here, but see <a href="https://bradleyboehmke.github.io/HOML/process.html">Boehmke and Greenwell (2020)</a>) and <strong>k-fold cross validation</strong>. An advantage of bootstrapping is that it provides an estimation of the distribution of the training error (without the need for data distribution assumptions because itâs non parametric), which informs not only the magnitude of the training error but also the variance of this estimate. Nevertheless, this statistical approach can become very computationally intensive because it needs many resamples with replacement and model runs. Hence cross validation lends itself more to model training.</p>
<p>In <em>k-fold cross validation</em>, the training data is split into <em>k</em> equally sized subsets (<em>folds</em>). (Donât confuse this k with the k in KNN.) Then, there will be <em>k</em> iterations, where each fold is used for validation once (while the remaining folds are used for training). An extreme case is <em>leave-one-out cross validation</em>, where <em>k</em> corresponds to the number of data points.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:kfoldcv"></span>
<img src="figures/cv.png" alt="K-fold cross validation. From Boehmke and Greenwell (2020)."  />
<p class="caption">
Figure 10.2: K-fold cross validation. From Boehmke and Greenwell (2020).
</p>
</div>
<p>To do a k-fold cross validation during model training in R, we donât have to implement the loops around folds ourselves. The resampling procedure can be specified in the {caret} function <code>train()</code> with the argument <code>trControl</code>. The object that this argument takes is the output of a function call to <code>trainControl()</code>. This can be implemented in two steps. For example, to do a 10-fold cross-validation, we can write:</p>
<!-- >>> CHECK FOR REDUCING COMPUTATIONAL COST TO RENDER BOOK ONLINE <<< -->
<!-- SAVE DATA WHEN RUNNING LOCALLY BY SETTING EVAL = TRUE, PUSH ONLY WITH EVAL = FALSE -->
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="supervisedmlii.html#cb387-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1982</span>)</span>
<span id="cb387-2"><a href="supervisedmlii.html#cb387-2" aria-hidden="true" tabindex="-1"></a>mod_cv <span class="ot">&lt;-</span> caret<span class="sc">::</span><span class="fu">train</span>(pp, </span>
<span id="cb387-3"><a href="supervisedmlii.html#cb387-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">data =</span> daily_fluxes_train <span class="sc">|&gt;</span> <span class="fu">drop_na</span>(), </span>
<span id="cb387-4"><a href="supervisedmlii.html#cb387-4" aria-hidden="true" tabindex="-1"></a>                       <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>,</span>
<span id="cb387-5"><a href="supervisedmlii.html#cb387-5" aria-hidden="true" tabindex="-1"></a>                       <span class="at">trControl =</span> caret<span class="sc">::</span><span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb387-6"><a href="supervisedmlii.html#cb387-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">tuneGrid =</span> <span class="fu">data.frame</span>(<span class="at">k =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">35</span>, <span class="dv">40</span>, <span class="dv">60</span>, <span class="dv">100</span>)),</span>
<span id="cb387-7"><a href="supervisedmlii.html#cb387-7" aria-hidden="true" tabindex="-1"></a>                       <span class="at">metric =</span> <span class="st">&quot;MAE&quot;</span>)</span></code></pre></div>
<!-- >>> END OF CHECK <<< -->
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="supervisedmlii.html#cb388-1" aria-hidden="true" tabindex="-1"></a><span class="co"># generic plot of the caret model object</span></span>
<span id="cb388-2"><a href="supervisedmlii.html#cb388-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mod_cv)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-211-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="supervisedmlii.html#cb389-1" aria-hidden="true" tabindex="-1"></a><span class="co"># generic print</span></span>
<span id="cb389-2"><a href="supervisedmlii.html#cb389-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(mod_cv)</span></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 1910 samples
##    8 predictor
## 
## Recipe steps: center, scale 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 1719, 1718, 1718, 1719, 1720, 1718, ... 
## Resampling results across tuning parameters:
## 
##   k    RMSE      Rsquared   MAE     
##     2  1.758390  0.5643266  1.331563
##     5  1.579795  0.6321707  1.199857
##    10  1.539660  0.6480432  1.163468
##    15  1.522924  0.6549458  1.155488
##    20  1.518210  0.6568319  1.152947
##    25  1.516940  0.6574409  1.151223
##    30  1.517698  0.6570899  1.153631
##    35  1.517916  0.6570457  1.153421
##    40  1.517559  0.6573507  1.153832
##    60  1.522451  0.6556145  1.161452
##   100  1.535410  0.6508217  1.177483
## 
## MAE was used to select the optimal model using the smallest value.
## The final value used for the model was k = 25.</code></pre>
<p>From the output of <code>print(mod_cv)</code>, we get information about model performance for each hyperparameter choice. The values reported are means of respective metrics determined across the ten folds. Also the optimal choice of <span class="math inline">\(k\)</span> (25) is reported. Does this correspond to the <span class="math inline">\(k\)</span> with the best performance determined on the test set? If resampling was a good approach to estimating out-of-sample model performance, then it should!</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="supervisedmlii.html#cb391-1" aria-hidden="true" tabindex="-1"></a>df_mae <span class="sc">|&gt;</span></span>
<span id="cb391-2"><a href="supervisedmlii.html#cb391-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(set <span class="sc">==</span> <span class="st">&quot;test&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb391-3"><a href="supervisedmlii.html#cb391-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(.estimate <span class="sc">==</span> <span class="fu">min</span>(.estimate))</span></code></pre></div>
<pre><code>## # A tibble: 1 Ã 6
##     idx .metric .estimator .estimate     k set  
##   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;
## 1     7 mae     standard        1.15    30 test</code></pre>
<p>The evaluation on the test set suggests that <span class="math inline">\(k=30\)</span> is optimal, while 10-fold cross-validation yielded an optimal <span class="math inline">\(k = 25\)</span>. Apparently, cross-validation suggested a model that is slightly more on the variance side along the bias-variance trade-off than the evaluation on the test set did. This (relatively small) mismatch is probably a result of randomness in the data.</p>
<p>Letâs look at the results as we did in Chapter <a href="supervisedmli.html#supervisedmli">9</a>. The model object <code>mod_cv</code> contains information about the whole hyperparameter search and also about the choice of the best hyperparameter value. When using the object in the <code>predict()</code> function (as used inside <code>eval_model()</code>), it automatically uses the model trained with the optimal <span class="math inline">\(k\)</span>.</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="supervisedmlii.html#cb393-1" aria-hidden="true" tabindex="-1"></a><span class="fu">eval_model</span>(<span class="at">mod =</span> mod_cv, <span class="at">df_train =</span> daily_fluxes_train, <span class="at">df_test =</span> daily_fluxes_test)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;
## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-213-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Remember that in Chapter <a href="supervisedmli.html#supervisedmli">9</a>, we used <span class="math inline">\(k=8\)</span> and got an <span class="math inline">\(R^2=0.72\)</span> on the training set and <span class="math inline">\(R^2=0.64\)</span> on the test set. The results with the optimal choice of <span class="math inline">\(k=25\)</span> yield an <span class="math inline">\(R^2=0.69\)</span> on the training set and <span class="math inline">\(R^2=0.65\)</span> on the test set - poorer than with <span class="math inline">\(k=8\)</span> on the training set but slightly better on the test set.</p>
</div>
<div id="validation-versus-testing-data" class="section level3 hasAnchor" number="10.2.5">
<h3><span class="header-section-number">10.2.5</span> Validation versus testing data<a href="supervisedmlii.html#validation-versus-testing-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A source of confusion can be the distinction of validation and testing data. They are different things. The validation data is used during model training. The model fitting and the selection of the optimal hyperparameters is based on comparing predictions with the validation data. Hence, evaluations of true out-of-sample predictions should be done with a portion of the data that has never been used during the model training process (see Figure <a href="supervisedmlii.html#fig:trainvaltest">10.3</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:trainvaltest"></span>
<img src="figures/training_validation_testing.png" alt="Figure adopted form [Google Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/validation/video-lecture)." width="80%" />
<p class="caption">
Figure 10.3: Figure adopted form <a href="https://developers.google.com/machine-learning/crash-course/validation/video-lecture">Google Machine Learning Crash Course</a>.
</p>
</div>
</div>
<div id="modeling-with-structured-data" class="section level3 hasAnchor" number="10.2.6">
<h3><span class="header-section-number">10.2.6</span> Modeling with structured data<a href="supervisedmlii.html#modeling-with-structured-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A fundamental assumption underlying many machine learning algorithms and their training setup is that the data are <em>independent and identically distributed (iid)</em>. This means that each observation is generated by the same process, follows the same distribution, and is independent from its neighboring point or any other data point. This assumption is often made in statistical models to simplify the analysis and to ensure the validity of various mathematical results used in machine learning algorithms. In reality, this is often not satisfied. In Chapter <a href="datawrangling.html#datawrangling">3</a>, we dealt with structure in the data in the context of formatting and aggregating data frames. Such structures are often also relevant for modelling and what it means for a model to âgeneralize wellâ. Remember that structure in data arises from similarity of the subjects generating the data. Such structures and their relation to the modelling task should be considered when choosing the model algorithm, formulating the model, and when implementing the training a testing setup.</p>
<p>Consider, for example, the time series of ecosystem fluxes and meterological covariates in our dataset <code>daily_fluxes</code>. When using this data to train a KNN or a linear regression model, we implicitly assume that the data is <em>iid</em>. We assumed that there is a true function <span class="math inline">\(f(X)\)</span> that generates the target data <span class="math inline">\(Y\)</span> and that can be used to predict under any novel condition <span class="math inline">\(X_\text{new}\)</span>. However, in reality, this may not be the case. <span class="math inline">\(f(X)\)</span> may change over time. For example, over the course of a season, the physiology of plants changes (think phenology) and may lead to temporally varying relationships between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> that are not captured by temporal variations in <span class="math inline">\(X\)</span> itself - the relationships are not stationary.</p>
<p>Working with geographic and environmental data, we often deal with <em>temporal dependencies</em> between predictors and the target data. In our data <code>daily_fluxes</code> of ecosystem fluxes and meteorological covariates, this may be, as mentioned, arising from phenological changes in plant physiology and structure, or caused by a lasting effects weather extremes (e.g., a late frost event in spring). In hydrological data, temporal dependencies between weather and streamflow are generated by catchment characteristics and the runoff generation processes. Such temporal dependencies violate the independence assumption. Certain machine learning algorithms (e.g., recurrent neural networks) offer a solution for such cases and are suited for modelling temporal dependencies or, in general, sequential data where the order of the records matters (e.g., language models that consider the order of words in a text). Training-testing and cross-validation splits for sequential data have to preserve the order of the data in the subsets. In this case, the splits have to be done by <em>blocks</em>. That is, model generalisability is to be assessed by training on one block of the time series and testing on the remaining block. Note that the splitting method introduced in Chapter <a href="supervisedmli.html#supervisedmli">9</a> using <code>rsample::initial_split()</code> assumes that the data is <em>iid</em>. In the function, data points are randomly drawn and allocated to either the test or the training subset. It is therefore not applicable for splitting data with temporal dependencies. Modelling temporal dependencies will be dealt in future (not currently available) chapters of this book.</p>
<p>Other dependencies may arise from the <em>spatial context.</em> For example, a model for classifying an atmospheric pressure field as a high or a low pressure system uses information about the spatial arrangement of the data - in this case raster data. A model predicts one value (âhigh pressure systemâ or âlow pressure systemâ) per pressure field. Such modelling tasks are dealt with yet another class of algorithms (e.g., convolutional neural networks).</p>
<p>Spatial or group-related structure in the data may arise if, in general, the processes generating the data, cannot be assumed to be identical and lead to identically distributed data across groups. For example, in the data <code>daily_fluxes_allsites_nested_joined</code> from Chapter <a href="datawrangling.html#datawrangling">3</a>, time series of ecosystem fluxes and meteorological covariates are provided for a set of different sites. There, the group structure is linked to site identity. Similarly, streamflow data may be available for multiple catchments. However, considering the between-catchment variations in soil, terrain, vegetation, and geology, a model may not yield accurate predictions when trained by data from one catchment and applied to a different catchment.</p>
<p>To evaluate model generalisability to a new site or catchment (not just a new time step within a single site or catchment), this structure has to be taken into consideration. In this, case, data splits of training and validation or testing subsets are to be separated along blocks, delineated by the similar groups of data points (by sites, or by catchments). That is, training data from a given site (or catchment) should be either in the training set or in the test (or validation) set, but not in both.</p>
<p>This illustrates that the data structure and the modelling aim (generalisability in what respect?) have to be accounted for when designing the data split and resampling strategy. The {caret} function <code>groupKFold()</code> offers the solution for such cases, creating folds for cross-validation that respect group delineations. In other cases, such grouping structure may not be evident and may not be reflected by information accessible for modelling. For example, we may be able to separate time series from different sites but we donât know whether sites are sufficiently independent to be able to consider the test metric to reflect the true uncertainty in predicting to an entirely new location which is neither in the test nor training set. In such cases, creative solutions have to be found and appropriate cross-validations have to be implemented with a view to the data structure and modelling aim.</p>
</div>
</div>
<div id="exercises-8" class="section level2 hasAnchor" number="10.3">
<h2><span class="header-section-number">10.3</span> Exercises<a href="supervisedmlii.html#exercises-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="cross-validation-by-hand" class="section level3 unnumbered hasAnchor">
<h3>Cross-validation by hand<a href="supervisedmlii.html#cross-validation-by-hand" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the tutorial we âbuilt on shoulder of giantsâ - people that went through the struggle of writing a robust package to implement a cross validation. Although we can and should use such packages, we still have to understand how a cross validation works in detail.</p>
<p>Write a function that implements <em>n</em>-fold cross-validation for KNN with <span class="math inline">\(k=30\)</span>. (We write ân-fold CVâ here to avoid confusion with the k in KNN, but mean the same as described in Section <a href="supervisedmlii.html#resampling">10.2.4</a>.) The function should take as arguments the training data object, <em>n</em> for specifying the number of folds (use <span class="math inline">\(n=60\)</span>), the name of the target variable, the names of the predictor variables as a character vector, and the <span class="math inline">\(k\)</span> for KNN. The function should return a vector of length <em>n</em>, containing the MAE evaluated on the <em>n</em> folds. To randomize the split of data points into folds, first âre-shuffleâ the rows in the training data as part of the function. Centering and scaling of the training and validation data should be applied manually before getting the KNN model object within each fold.</p>
<p>As data, use daily ecosystem flux data from <a href="./data/df_daily_exercise_supervisedmlii.csv">here</a>. As target variable, use <code>"GPP_NT_VUT_REF"</code>. As predictor variables, use <code>c("TA_F", "SW_IN_F", "VPD_F")</code>.</p>
<p>Visualise the distribution of the validation errors (MAE) across folds.</p>
<blockquote>
<p>Hint: Center and scale the predictors (but not the target data) within each fold.</p>
</blockquote>
<blockquote>
<p>Hint: Use <code>read.csv()</code> to obtain a ânudeâ data frame (not a tibble) and use the syntax <code>df[,"variable_name"]</code> to extract a vector from a data frame. This makes your life easier.</p>
</blockquote>
<blockquote>
<p>Hint: To determine the row indices to be allocated to each fold, you may find a solution using the base-R function <code>split()</code> or you may use <code>caret::createFolds()</code>.</p>
</blockquote>
<blockquote>
<p>Hint: Write two functions: One as asked for above and one that implements steps that are carried out repeatedly for each fold, given row indices of the validation set of the respective fold.</p>
</blockquote>
<blockquote>
<p>Hint: Since you are doing the cross-validation âby handâ and perform no hyperparameter tuning, we donât need the <code>caret::train()</code> function. Instead, use <code>caret::knnreg(x, y, ...)</code> for creating the model object on the training data (with <code>x</code> and <code>y</code> being data frames) and the generic <code>predict()</code> for predicting on the validation set within each fold.</p>
</blockquote>
</div>
<div id="cross-validation-vs.-test-error" class="section level3 hasAnchor" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> Cross-validation vs.Â test error<a href="supervisedmlii.html#cross-validation-vs.-test-error" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, you can use the user-friendly <code>caret::train()</code> for KNN with 60-fold cross-validation and tuning the hyperparameter k. Use the MAE as the loss metric. Use the same data as in the Exercise above and withhold 20% of the data for the test set. Visually compare the reported mean MAE from the cross-validation folds with the MAE determined on a test set.</p>
<p>In your visual comparison, add a plot layer showing the distribution of validation errors from you manual implementation of cross-validation (Exercise above).</p>
<blockquote>
<p>Hint: The returned model object from a <code>caret::train()</code> call is a list with fold-wise metrics in its element <code>results</code>.</p>
</blockquote>
</div>
</div>
<div id="report-exercises-3" class="section level2 hasAnchor" number="10.4">
<h2><span class="header-section-number">10.4</span> Report Exercises<a href="supervisedmlii.html#report-exercises-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here, we explore the role of structure in the data for model generalisability and how to best estimate a âtrueâ out-of-sample error that corresponds to the prediction task. The task here is to train a model on ecosystem flux observations from one site and predict to another site (spatially upscaling). In previous examples and exercises, we always trained and predicted within the same site. How well is a model generalisable to a new site?</p>
<p>We investigate this question using ecosystem flux data from two distinct sites: <a href="https://fluxnet.org/sites/siteinfo/CH-Dav">Davos (CH-Dav)</a> (<code>FLX_CH-Dav_FLUXNET2015_FULLSET_DD_1997-2014_1-3.csv</code>), and <a href="https://fluxnet.org/sites/siteinfo/CH-Lae">Laegern (CH-Lae)</a> (<code>FLX_CH-Lae_FLUXNET2015_FULLSET_DD_2004-2014_1-4.csv</code>). Again, use KNN and tune K for each model. Both sites are registered in the FLUXNET network.</p>
<p>Proceed as follows:</p>
<ul>
<li>Set aside 20% of the data of each site for testing.</li>
<li>Compare within-site predictions and across-site predictions on the test set for both sites, considering different metrics. For across-site predictions, make sure to implement a train and test setup that enables a true out-of-sample prediction test.</li>
<li>Train a single model with training data pooled from both sites and predict with this single model on the test data of both sites. How do the model metrics on the test set compare to the true out-of-sample setup above? Interpret differences. Is it a valid approach to perform model training like this? Use your knowledge about structure in the data and its relevance for the model training setup.</li>
<li>Get information about the characteristics of the two sites. What are the differences in terms of climate, vegetation, altitude, etc. between the Davos and Laegern sites? Interpret biases of the out-of-sample predictions with a view to the site characteristics.</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="supervisedmli.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="randomforest.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
