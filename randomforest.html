<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Random Forest | Applied Geodata Science</title>
  <meta name="description" content="This course prepares you to benefit from the general data richness in environmental and geo-sciences." />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Random Forest | Applied Geodata Science" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This course prepares you to benefit from the general data richness in environmental and geo-sciences." />
  <meta name="github-repo" content="stineb/agsd" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Random Forest | Applied Geodata Science" />
  
  <meta name="twitter:description" content="This course prepares you to benefit from the general data richness in environmental and geo-sciences." />
  

<meta name="author" content="Benjamin Stocker (lead), Koen Hufkens (contributing), Pepa ArÃ¡n (contributing), Pascal Schneider (contributing)" />


<meta name="date" content="2023-02-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="figures/apple-touch-icon.png" />
  <link rel="shortcut icon" href="figures/favicon.ico" type="image/x-icon" />
<link rel="prev" href="supervisedmlii.html"/>
<link rel="next" href="solutions.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied Geodata Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i>About this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-course"><i class="fa fa-check"></i>About this course</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-goal"><i class="fa fa-check"></i>Course goal</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-objectives"><i class="fa fa-check"></i>Learning Objectives</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-contents"><i class="fa fa-check"></i>Course contents</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#what-is-applied-geodata-science"><i class="fa fa-check"></i>What is Applied Geodata Science?</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#the-data-science-workflow"><i class="fa fa-check"></i>The data science workflow</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#why-now"><i class="fa fa-check"></i>Why now?</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#a-new-modelling-paradigm"><i class="fa fa-check"></i>A new modelling paradigm</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#reading-and-link-collection"><i class="fa fa-check"></i>Reading and link collection</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="gettingstarted.html"><a href="gettingstarted.html"><i class="fa fa-check"></i><b>1</b> Getting started</a>
<ul>
<li class="chapter" data-level="1.1" data-path="gettingstarted.html"><a href="gettingstarted.html#learning-objectives-1"><i class="fa fa-check"></i><b>1.1</b> Learning objectives</a></li>
<li class="chapter" data-level="1.2" data-path="gettingstarted.html"><a href="gettingstarted.html#tutorial"><i class="fa fa-check"></i><b>1.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="gettingstarted.html"><a href="gettingstarted.html#working-with-r-and-rstudio"><i class="fa fa-check"></i><b>1.2.1</b> Working with R and RStudio</a></li>
<li class="chapter" data-level="1.2.2" data-path="gettingstarted.html"><a href="gettingstarted.html#r-objects"><i class="fa fa-check"></i><b>1.2.2</b> R objects</a></li>
<li class="chapter" data-level="1.2.3" data-path="gettingstarted.html"><a href="gettingstarted.html#r-environment"><i class="fa fa-check"></i><b>1.2.3</b> R environment</a></li>
<li class="chapter" data-level="1.2.4" data-path="gettingstarted.html"><a href="gettingstarted.html#libraries"><i class="fa fa-check"></i><b>1.2.4</b> Libraries</a></li>
<li class="chapter" data-level="1.2.5" data-path="gettingstarted.html"><a href="gettingstarted.html#r-scripts"><i class="fa fa-check"></i><b>1.2.5</b> R scripts</a></li>
<li class="chapter" data-level="1.2.6" data-path="gettingstarted.html"><a href="gettingstarted.html#rmarkdown"><i class="fa fa-check"></i><b>1.2.6</b> R Markdown</a></li>
<li class="chapter" data-level="1.2.7" data-path="gettingstarted.html"><a href="gettingstarted.html#wspmgmt"><i class="fa fa-check"></i><b>1.2.7</b> Workspace management</a></li>
<li class="chapter" data-level="1.2.8" data-path="gettingstarted.html"><a href="gettingstarted.html#setup"><i class="fa fa-check"></i><b>1.2.8</b> Setup</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="gettingstarted.html"><a href="gettingstarted.html#exercises"><i class="fa fa-check"></i><b>1.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#dimensions-of-a-circle"><i class="fa fa-check"></i>Dimensions of a circle</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#sequence-of-numbers"><i class="fa fa-check"></i>Sequence of numbers</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#gauss-sum"><i class="fa fa-check"></i>Gauss sum</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#magic-trick-algorithm"><i class="fa fa-check"></i>Magic trick algorithm</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#vectors-1"><i class="fa fa-check"></i>Vectors</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#data-frames-1"><i class="fa fa-check"></i>Data frames</a></li>
<li class="chapter" data-level="" data-path="gettingstarted.html"><a href="gettingstarted.html#workspace"><i class="fa fa-check"></i>Workspace</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="programmingprimers.html"><a href="programmingprimers.html"><i class="fa fa-check"></i><b>2</b> Programming primers</a>
<ul>
<li class="chapter" data-level="2.1" data-path="programmingprimers.html"><a href="programmingprimers.html#learning-objectives-2"><i class="fa fa-check"></i><b>2.1</b> Learning objectives</a></li>
<li class="chapter" data-level="2.2" data-path="programmingprimers.html"><a href="programmingprimers.html#tutorial-1"><i class="fa fa-check"></i><b>2.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="programmingprimers.html"><a href="programmingprimers.html#programming-basics"><i class="fa fa-check"></i><b>2.2.1</b> Programming basics</a></li>
<li class="chapter" data-level="2.2.2" data-path="programmingprimers.html"><a href="programmingprimers.html#style-your-code"><i class="fa fa-check"></i><b>2.2.2</b> Style your code</a></li>
<li class="chapter" data-level="2.2.3" data-path="programmingprimers.html"><a href="programmingprimers.html#findinghelp"><i class="fa fa-check"></i><b>2.2.3</b> Where to find help</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="programmingprimers.html"><a href="programmingprimers.html#exercises-1"><i class="fa fa-check"></i><b>2.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="programmingprimers.html"><a href="programmingprimers.html#gauss-variations"><i class="fa fa-check"></i>Gauss variations</a></li>
<li class="chapter" data-level="" data-path="programmingprimers.html"><a href="programmingprimers.html#nested-loops"><i class="fa fa-check"></i>Nested loops</a></li>
<li class="chapter" data-level="" data-path="programmingprimers.html"><a href="programmingprimers.html#interpolation"><i class="fa fa-check"></i>Interpolation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="datawrangling.html"><a href="datawrangling.html"><i class="fa fa-check"></i><b>3</b> Data wrangling</a>
<ul>
<li class="chapter" data-level="3.1" data-path="datawrangling.html"><a href="datawrangling.html#learning-objectives-3"><i class="fa fa-check"></i><b>3.1</b> Learning objectives</a></li>
<li class="chapter" data-level="3.2" data-path="datawrangling.html"><a href="datawrangling.html#tutorial-2"><i class="fa fa-check"></i><b>3.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="datawrangling.html"><a href="datawrangling.html#example-data"><i class="fa fa-check"></i><b>3.2.1</b> Example data</a></li>
<li class="chapter" data-level="3.2.2" data-path="datawrangling.html"><a href="datawrangling.html#tidyverse"><i class="fa fa-check"></i><b>3.2.2</b> Tidyverse</a></li>
<li class="chapter" data-level="3.2.3" data-path="datawrangling.html"><a href="datawrangling.html#reading-tabular-data"><i class="fa fa-check"></i><b>3.2.3</b> Reading tabular data</a></li>
<li class="chapter" data-level="3.2.4" data-path="datawrangling.html"><a href="datawrangling.html#variable-selection"><i class="fa fa-check"></i><b>3.2.4</b> Variable selection</a></li>
<li class="chapter" data-level="3.2.5" data-path="datawrangling.html"><a href="datawrangling.html#time-objects"><i class="fa fa-check"></i><b>3.2.5</b> Time objects</a></li>
<li class="chapter" data-level="3.2.6" data-path="datawrangling.html"><a href="datawrangling.html#variable-re--definition"><i class="fa fa-check"></i><b>3.2.6</b> Variable (re-) definition</a></li>
<li class="chapter" data-level="3.2.7" data-path="datawrangling.html"><a href="datawrangling.html#axes-of-variation"><i class="fa fa-check"></i><b>3.2.7</b> Axes of variation</a></li>
<li class="chapter" data-level="3.2.8" data-path="datawrangling.html"><a href="datawrangling.html#tidydata"><i class="fa fa-check"></i><b>3.2.8</b> Tidy data</a></li>
<li class="chapter" data-level="3.2.9" data-path="datawrangling.html"><a href="datawrangling.html#aggregating-data"><i class="fa fa-check"></i><b>3.2.9</b> Aggregating data</a></li>
<li class="chapter" data-level="3.2.10" data-path="datawrangling.html"><a href="datawrangling.html#data-cleaning"><i class="fa fa-check"></i><b>3.2.10</b> Data cleaning</a></li>
<li class="chapter" data-level="3.2.11" data-path="datawrangling.html"><a href="datawrangling.html#writing-data-to-csv"><i class="fa fa-check"></i><b>3.2.11</b> Writing data to CSV</a></li>
<li class="chapter" data-level="3.2.12" data-path="datawrangling.html"><a href="datawrangling.html#combining-relational-data"><i class="fa fa-check"></i><b>3.2.12</b> Combining relational data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="datawrangling.html"><a href="datawrangling.html#extramaterialwrangling"><i class="fa fa-check"></i><b>3.3</b> Extra material</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="datawrangling.html"><a href="datawrangling.html#functional-programming-i"><i class="fa fa-check"></i><b>3.3.1</b> Functional programming I</a></li>
<li class="chapter" data-level="3.3.2" data-path="datawrangling.html"><a href="datawrangling.html#strings"><i class="fa fa-check"></i><b>3.3.2</b> Strings</a></li>
<li class="chapter" data-level="3.3.3" data-path="datawrangling.html"><a href="datawrangling.html#functional-programming-ii"><i class="fa fa-check"></i><b>3.3.3</b> Functional programming II</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="datawrangling.html"><a href="datawrangling.html#exerciseswrangling"><i class="fa fa-check"></i><b>3.4</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="datawrangling.html"><a href="datawrangling.html#aggregation-of-data-in-tidy-style"><i class="fa fa-check"></i>Aggregation of data in tidy style</a></li>
<li class="chapter" data-level="" data-path="datawrangling.html"><a href="datawrangling.html#when-is-gpp-actually-measured"><i class="fa fa-check"></i>When is GPP actually measured?</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="datawrangling.html"><a href="datawrangling.html#report-exercise"><i class="fa fa-check"></i><b>3.5</b> Report Exercise</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="datavis.html"><a href="datavis.html"><i class="fa fa-check"></i><b>4</b> Data visualisation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="datavis.html"><a href="datavis.html#learning-objectives-4"><i class="fa fa-check"></i><b>4.1</b> Learning objectives</a></li>
<li class="chapter" data-level="4.2" data-path="datavis.html"><a href="datavis.html#tutorial-3"><i class="fa fa-check"></i><b>4.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="datavis.html"><a href="datavis.html#the-grammar-of-graphics"><i class="fa fa-check"></i><b>4.2.1</b> The grammar of graphics</a></li>
<li class="chapter" data-level="4.2.2" data-path="datavis.html"><a href="datavis.html#every-data-has-its-representation"><i class="fa fa-check"></i><b>4.2.2</b> Every data has its representation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="datavis.html"><a href="datavis.html#exercises-2"><i class="fa fa-check"></i><b>4.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="datavis.html"><a href="datavis.html#identifying-outliers"><i class="fa fa-check"></i>Identifying Outliers</a></li>
<li class="chapter" data-level="" data-path="datavis.html"><a href="datavis.html#visualising-diurnal-and-seasonal-cycles-of-gpp"><i class="fa fa-check"></i>Visualising diurnal and seasonal cycles of GPP</a></li>
<li class="chapter" data-level="" data-path="datavis.html"><a href="datavis.html#trend-in-carbon-dioxide-concentrations"><i class="fa fa-check"></i>Trend in carbon dioxide concentrations</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="datavis.html"><a href="datavis.html#report-exercises"><i class="fa fa-check"></i><b>4.4</b> Report Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="datavis.html"><a href="datavis.html#telling-a-story-from-data"><i class="fa fa-check"></i>Telling a story from data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="datavariety.html"><a href="datavariety.html"><i class="fa fa-check"></i><b>5</b> Data variety</a>
<ul>
<li class="chapter" data-level="5.1" data-path="datavariety.html"><a href="datavariety.html#learning-objectives-5"><i class="fa fa-check"></i><b>5.1</b> Learning objectives</a></li>
<li class="chapter" data-level="5.2" data-path="datavariety.html"><a href="datavariety.html#tutorial-4"><i class="fa fa-check"></i><b>5.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="datavariety.html"><a href="datavariety.html#files-and-file-formats"><i class="fa fa-check"></i><b>5.2.1</b> Files and file formats</a></li>
<li class="chapter" data-level="5.2.2" data-path="datavariety.html"><a href="datavariety.html#meta-data"><i class="fa fa-check"></i><b>5.2.2</b> Meta-data</a></li>
<li class="chapter" data-level="5.2.3" data-path="datavariety.html"><a href="datavariety.html#spatial-data-representation"><i class="fa fa-check"></i><b>5.2.3</b> Spatial data representation</a></li>
<li class="chapter" data-level="5.2.4" data-path="datavariety.html"><a href="datavariety.html#online-data-sources"><i class="fa fa-check"></i><b>5.2.4</b> Online data sources</a></li>
<li class="chapter" data-level="5.2.5" data-path="datavariety.html"><a href="datavariety.html#example-environmental-data-repositories"><i class="fa fa-check"></i><b>5.2.5</b> Example environmental data repositories</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="datavariety.html"><a href="datavariety.html#exercises-3"><i class="fa fa-check"></i><b>5.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="datavariety.html"><a href="datavariety.html#files-and-file-formats-1"><i class="fa fa-check"></i>Files and file formats</a></li>
<li class="chapter" data-level="" data-path="datavariety.html"><a href="datavariety.html#api-use"><i class="fa fa-check"></i>API use</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="openscience.html"><a href="openscience.html"><i class="fa fa-check"></i><b>6</b> Open science practices</a>
<ul>
<li class="chapter" data-level="6.1" data-path="openscience.html"><a href="openscience.html#learning-objectives-6"><i class="fa fa-check"></i><b>6.1</b> Learning objectives</a></li>
<li class="chapter" data-level="6.2" data-path="openscience.html"><a href="openscience.html#tutorial-5"><i class="fa fa-check"></i><b>6.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="openscience.html"><a href="openscience.html#project-structure"><i class="fa fa-check"></i><b>6.2.1</b> Project structure</a></li>
<li class="chapter" data-level="6.2.2" data-path="openscience.html"><a href="openscience.html#managing-workflows"><i class="fa fa-check"></i><b>6.2.2</b> Managing workflows</a></li>
<li class="chapter" data-level="6.2.3" data-path="openscience.html"><a href="openscience.html#capturing-your-session-state"><i class="fa fa-check"></i><b>6.2.3</b> Capturing your session state</a></li>
<li class="chapter" data-level="6.2.4" data-path="openscience.html"><a href="openscience.html#capturing-a-system-state"><i class="fa fa-check"></i><b>6.2.4</b> Capturing a system state</a></li>
<li class="chapter" data-level="6.2.5" data-path="openscience.html"><a href="openscience.html#readable-reporting-using-rmarkdown"><i class="fa fa-check"></i><b>6.2.5</b> Readable reporting using Rmarkdown</a></li>
<li class="chapter" data-level="6.2.6" data-path="openscience.html"><a href="openscience.html#data-retention"><i class="fa fa-check"></i><b>6.2.6</b> Data retention</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="openscience.html"><a href="openscience.html#exercises-4"><i class="fa fa-check"></i><b>6.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="openscience.html"><a href="openscience.html#external-data"><i class="fa fa-check"></i>External data</a></li>
<li class="chapter" data-level="" data-path="openscience.html"><a href="openscience.html#a-new-project"><i class="fa fa-check"></i>A new project</a></li>
<li class="chapter" data-level="" data-path="openscience.html"><a href="openscience.html#tracking-the-state-of-your-project"><i class="fa fa-check"></i>Tracking the state of your project</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="codemgmt.html"><a href="codemgmt.html"><i class="fa fa-check"></i><b>7</b> Code management</a>
<ul>
<li class="chapter" data-level="7.1" data-path="codemgmt.html"><a href="codemgmt.html#learning-objectives-7"><i class="fa fa-check"></i><b>7.1</b> Learning objectives</a></li>
<li class="chapter" data-level="7.2" data-path="codemgmt.html"><a href="codemgmt.html#tutorial-6"><i class="fa fa-check"></i><b>7.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="codemgmt.html"><a href="codemgmt.html#gitworkflow"><i class="fa fa-check"></i><b>7.2.1</b> Git and local version control</a></li>
<li class="chapter" data-level="7.2.2" data-path="codemgmt.html"><a href="codemgmt.html#remote-version-control"><i class="fa fa-check"></i><b>7.2.2</b> Remote version control</a></li>
<li class="chapter" data-level="7.2.3" data-path="codemgmt.html"><a href="codemgmt.html#location-based-code-management---github-templates"><i class="fa fa-check"></i><b>7.2.3</b> Location based code management - github templates</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="codemgmt.html"><a href="codemgmt.html#exercises-5"><i class="fa fa-check"></i><b>7.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="codemgmt.html"><a href="codemgmt.html#location-based-code-management"><i class="fa fa-check"></i>Location based code management</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="codemgmt.html"><a href="codemgmt.html#report-exercises-1"><i class="fa fa-check"></i><b>7.4</b> Report Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="codemgmt.html"><a href="codemgmt.html#collaborative-work-on-github"><i class="fa fa-check"></i>Collaborative Work on Github</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regressionclassification.html"><a href="regressionclassification.html"><i class="fa fa-check"></i><b>8</b> Regression and classification</a>
<ul>
<li class="chapter" data-level="8.1" data-path="regressionclassification.html"><a href="regressionclassification.html#learning-objectives-8"><i class="fa fa-check"></i><b>8.1</b> Learning objectives</a></li>
<li class="chapter" data-level="8.2" data-path="regressionclassification.html"><a href="regressionclassification.html#tutorial-7"><i class="fa fa-check"></i><b>8.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="regressionclassification.html"><a href="regressionclassification.html#types-of-models"><i class="fa fa-check"></i><b>8.2.1</b> Types of models</a></li>
<li class="chapter" data-level="8.2.2" data-path="regressionclassification.html"><a href="regressionclassification.html#regression"><i class="fa fa-check"></i><b>8.2.2</b> Regression</a></li>
<li class="chapter" data-level="8.2.3" data-path="regressionclassification.html"><a href="regressionclassification.html#classification"><i class="fa fa-check"></i><b>8.2.3</b> Classification</a></li>
<li class="chapter" data-level="8.2.4" data-path="regressionclassification.html"><a href="regressionclassification.html#model-evaluation"><i class="fa fa-check"></i><b>8.2.4</b> Model evaluation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="regressionclassification.html"><a href="regressionclassification.html#exercises-6"><i class="fa fa-check"></i><b>8.3</b> Exercises</a></li>
<li class="chapter" data-level="8.4" data-path="regressionclassification.html"><a href="regressionclassification.html#report-exercise-1"><i class="fa fa-check"></i><b>8.4</b> Report Exercise</a>
<ul>
<li class="chapter" data-level="" data-path="regressionclassification.html"><a href="regressionclassification.html#stepwise-regression-and-asking-for-help"><i class="fa fa-check"></i>Stepwise regression and asking for help</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="supervisedmli.html"><a href="supervisedmli.html"><i class="fa fa-check"></i><b>9</b> Supervised machine learning I</a>
<ul>
<li class="chapter" data-level="9.1" data-path="supervisedmli.html"><a href="supervisedmli.html#learning-objectives-9"><i class="fa fa-check"></i><b>9.1</b> Learning objectives</a></li>
<li class="chapter" data-level="9.2" data-path="supervisedmli.html"><a href="supervisedmli.html#tutorial-8"><i class="fa fa-check"></i><b>9.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="supervisedmli.html"><a href="supervisedmli.html#what-is-supervised-machine-learning"><i class="fa fa-check"></i><b>9.2.1</b> What is supervised machine learning?</a></li>
<li class="chapter" data-level="9.2.2" data-path="supervisedmli.html"><a href="supervisedmli.html#overfitting"><i class="fa fa-check"></i><b>9.2.2</b> Overfitting</a></li>
<li class="chapter" data-level="9.2.3" data-path="supervisedmli.html"><a href="supervisedmli.html#data-and-the-modelling-challenge"><i class="fa fa-check"></i><b>9.2.3</b> Data and the modelling challenge</a></li>
<li class="chapter" data-level="9.2.4" data-path="supervisedmli.html"><a href="supervisedmli.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>9.2.4</b> K-nearest neighbours</a></li>
<li class="chapter" data-level="9.2.5" data-path="supervisedmli.html"><a href="supervisedmli.html#model-formulation"><i class="fa fa-check"></i><b>9.2.5</b> Model formulation</a></li>
<li class="chapter" data-level="9.2.6" data-path="supervisedmli.html"><a href="supervisedmli.html#data-splitting"><i class="fa fa-check"></i><b>9.2.6</b> Data splitting</a></li>
<li class="chapter" data-level="9.2.7" data-path="supervisedmli.html"><a href="supervisedmli.html#preprocessing"><i class="fa fa-check"></i><b>9.2.7</b> Pre-processing</a></li>
<li class="chapter" data-level="9.2.8" data-path="supervisedmli.html"><a href="supervisedmli.html#putting-it-all-together-half-way"><i class="fa fa-check"></i><b>9.2.8</b> Putting it all together (half-way)</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="supervisedmli.html"><a href="supervisedmli.html#report-exercises-2"><i class="fa fa-check"></i><b>9.3</b> Report Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="supervisedmlii.html"><a href="supervisedmlii.html"><i class="fa fa-check"></i><b>10</b> Supervised machine learning II</a>
<ul>
<li class="chapter" data-level="10.1" data-path="supervisedmlii.html"><a href="supervisedmlii.html#learning-objectives-10"><i class="fa fa-check"></i><b>10.1</b> Learning objectives</a></li>
<li class="chapter" data-level="10.2" data-path="supervisedmlii.html"><a href="supervisedmlii.html#tutorial-9"><i class="fa fa-check"></i><b>10.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="supervisedmlii.html"><a href="supervisedmlii.html#data-and-the-modelling-challenge-1"><i class="fa fa-check"></i><b>10.2.1</b> Data and the modelling challenge</a></li>
<li class="chapter" data-level="10.2.2" data-path="supervisedmlii.html"><a href="supervisedmlii.html#training"><i class="fa fa-check"></i><b>10.2.2</b> Loss function</a></li>
<li class="chapter" data-level="10.2.3" data-path="supervisedmlii.html"><a href="supervisedmlii.html#hyperparameters"><i class="fa fa-check"></i><b>10.2.3</b> Hyperparameters</a></li>
<li class="chapter" data-level="10.2.4" data-path="supervisedmlii.html"><a href="supervisedmlii.html#resampling"><i class="fa fa-check"></i><b>10.2.4</b> Resampling</a></li>
<li class="chapter" data-level="10.2.5" data-path="supervisedmlii.html"><a href="supervisedmlii.html#validation-versus-testing-data"><i class="fa fa-check"></i><b>10.2.5</b> Validation versus testing data</a></li>
<li class="chapter" data-level="10.2.6" data-path="supervisedmlii.html"><a href="supervisedmlii.html#modeling-with-structured-data"><i class="fa fa-check"></i><b>10.2.6</b> Modeling with structured data</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="supervisedmlii.html"><a href="supervisedmlii.html#exercises-7"><i class="fa fa-check"></i><b>10.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="supervisedmlii.html"><a href="supervisedmlii.html#implement-a-k-fold-cross-validation-by-hand."><i class="fa fa-check"></i><b>10.3.1</b> Implement a k-fold cross validation by hand.</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="supervisedmlii.html"><a href="supervisedmlii.html#report-exercises-3"><i class="fa fa-check"></i><b>10.4</b> Report Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="randomforest.html"><a href="randomforest.html"><i class="fa fa-check"></i><b>11</b> Random Forest</a>
<ul>
<li class="chapter" data-level="11.1" data-path="randomforest.html"><a href="randomforest.html#learning-objectives-11"><i class="fa fa-check"></i><b>11.1</b> Learning objectives</a></li>
<li class="chapter" data-level="11.2" data-path="randomforest.html"><a href="randomforest.html#tutorial-10"><i class="fa fa-check"></i><b>11.2</b> Tutorial</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="randomforest.html"><a href="randomforest.html#decision-trees"><i class="fa fa-check"></i><b>11.2.1</b> Decision trees</a></li>
<li class="chapter" data-level="11.2.2" data-path="randomforest.html"><a href="randomforest.html#bagging"><i class="fa fa-check"></i><b>11.2.2</b> Bagging</a></li>
<li class="chapter" data-level="11.2.3" data-path="randomforest.html"><a href="randomforest.html#from-trees-to-a-forest"><i class="fa fa-check"></i><b>11.2.3</b> From trees to a forest</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="randomforest.html"><a href="randomforest.html#exercises-8"><i class="fa fa-check"></i><b>11.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="" data-path="randomforest.html"><a href="randomforest.html#fitting-a-random-forest"><i class="fa fa-check"></i>Fitting a Random Forest</a></li>
<li class="chapter" data-level="" data-path="randomforest.html"><a href="randomforest.html#hyperparameter-tuning"><i class="fa fa-check"></i>Hyperparameter tuning</a></li>
<li class="chapter" data-level="" data-path="randomforest.html"><a href="randomforest.html#model-performance"><i class="fa fa-check"></i>Model performance</a></li>
<li class="chapter" data-level="11.3.1" data-path="randomforest.html"><a href="randomforest.html#xxx-solution"><i class="fa fa-check"></i><b>11.3.1</b> XXX Solution</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="solutions.html"><a href="solutions.html"><i class="fa fa-check"></i><b>A</b> Solutions</a>
<ul>
<li class="chapter" data-level="A.1" data-path="solutions.html"><a href="solutions.html#getting-started"><i class="fa fa-check"></i><b>A.1</b> Getting Started</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#dimensions-of-a-circle-1"><i class="fa fa-check"></i>Dimensions of a circle</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#sequence-of-numbers-1"><i class="fa fa-check"></i>Sequence of numbers</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#gauss-sum-1"><i class="fa fa-check"></i>Gauss sum</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#magic-trick-algorithm-1"><i class="fa fa-check"></i>Magic trick algorithm</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#vectors-2"><i class="fa fa-check"></i>Vectors</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#data-frames-2"><i class="fa fa-check"></i>Data frames</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#workspace-1"><i class="fa fa-check"></i>Workspace</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="solutions.html"><a href="solutions.html#programming-primers"><i class="fa fa-check"></i><b>A.2</b> Programming primers</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#gauss-variations-1"><i class="fa fa-check"></i>Gauss variations</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#nested-loops-1"><i class="fa fa-check"></i>Nested loops</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#interpolation-1"><i class="fa fa-check"></i>Interpolation</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="solutions.html"><a href="solutions.html#random-forest"><i class="fa fa-check"></i><b>A.3</b> Random Forest</a>
<ul>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#fitting-a-random-forest-1"><i class="fa fa-check"></i>Fitting a Random Forest</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#hyperparameter-tuning-1"><i class="fa fa-check"></i>Hyperparameter tuning</a></li>
<li class="chapter" data-level="" data-path="solutions.html"><a href="solutions.html#model-performance-1"><i class="fa fa-check"></i>Model performance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>B</b> References</a>
<ul>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html#system-information-and-package-list"><i class="fa fa-check"></i>System information and package list</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Geodata Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="randomforest" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Chapter 11</span> Random Forest<a href="randomforest.html#randomforest" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><strong>Chapter lead author: Benjamin Stocker</strong></p>
<div id="learning-objectives-11" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Learning objectives<a href="randomforest.html#learning-objectives-11" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter you will learn how to implement a random forest model.</p>
<p>You will learn among others:</p>
<ul>
<li>the principles of a decision tree, and what is bagging</li>
<li>how decision trees are related to random forest methods</li>
</ul>
</div>
<div id="tutorial-10" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Tutorial<a href="randomforest.html#tutorial-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="decision-trees" class="section level3 hasAnchor" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Decision trees<a href="randomforest.html#decision-trees" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Just as a forest consists of trees, a <em>Random Forest</em> model consists of <em>decision trees.</em> Therefore, letâs start with a decision tree, also known as CART (classification and regression tree). Consider a similar example as in Chapter <a href="supervisedmli.html#supervisedmli">9</a> where we fitted a function <span class="math inline">\(Y = f(X)\)</span> with polynomials. Instead, here we fit it with a decision tree. The tree grows by successively splitting (branching) the predictor range (<span class="math inline">\(X\)</span>) into binary classes (two regions along <span class="math inline">\(X\)</span>) and predicting a different and constant value <span class="math inline">\(c\)</span> for the target variable on either side of the split. The location of the split is chosen such that the overall error between the observed response (<span class="math inline">\(Y_i\)</span>) and the predicted constant (<span class="math inline">\(c_i\)</span>) is minimized. The error is determined based on whether weâre dealing with a regression or a classification problem.</p>
<ul>
<li>For regression problems, the <em>sum of square errors</em> is minimized.</li>
</ul>
<p><span class="math display">\[
    \text{SSE} = \sum_i{(\hat{Y_i}-Y_i)^2}
\]</span></p>
<ul>
<li>For classification problems, the <em>cross-entropy</em> or the <em>Gini index</em> are typically maximized. Both are measures of the difference between probability distributions (main ideas in <a href="https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451">this blogpost</a>).</li>
</ul>
<p><img src="_main_files/figure-html/unnamed-chunk-207-1.png" width="672" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-207-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>As a tree grows, splits are recursively added. In our example, only one predictor variable is available. The splits are therefore performed always on the same variable, splitting up <span class="math inline">\(X\)</span> further.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-208-1.png" width="672" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-208-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>In the visualisation of the decision tree above, the uppermost decision is the <em>root node</em>. From there, two branches connect to <em>internal nodes</em>, and at the bottom of the tree are the <em>leaf nodes</em>. (The nature-aware reader may note that leaves are typically at the top, and roots at the bottom of a tree. Nevermind.)</p>
<p>Typically, multiple predictor variables are available. For each split, the variable and the location of the split along that variable is determined to satisfy the respective criteria for regression and classification.</p>
<p>Decision trees are high variance learners. That is, as the maximum tree depth is increased, the variance of predictions increases. In other words, the depth of a tree controls the model complexity and the bias-variance trade-off. With excessive depth, decision trees tend to overfit.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-209-1.png" width="672" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-209-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>An advantage of decision trees is that they require minimal pre-processing of the data and they are robust to outliers. This is thanks to their approach of converting continuous variables into binary classes for predictions. Hence, they can naturally handle a mix of continuous and categorical predictor variables. Furthermore, predictions are not sensitive to the distance of a predictor variableâs value to a respective variableâs split location. This makes decision trees robust to outliers. It also implies that predictions to unseen data points that lie outside the range of values in the training data (<em>extrapolation</em>) are conservative.</p>
<p>The disadvantage is, as demonstrated above, the tendency towards high variance of predictions when models get complex (deep trees). And thus, decision trees tend to be outperformed by other algorithms.</p>
</div>
<div id="bagging" class="section level3 hasAnchor" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> Bagging<a href="randomforest.html#bagging" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The approach of <em>bagging</em> is to smooth out the high variance of decision tree predictions by averaging over multiple, slightly differet trees. Differences between the trees are introduced by bagging, that is, by training each individual tree only on a bootstrapped sample of the full training data. Here, a decision tree has the role of a <em>base learner</em> and bagging takes an ensemble approach. Final predictions are then taken as the average (for regression) or the most frequent class (for classification) across all treesâ predictions.</p>
<p>Bagging is particularly effective when the base learner tends to have a high variance. The variance of predictions is continuously reduced with an increasing number of decision trees, over which averages are taken, and no tendency to overfit results from increasing the number of trees. However, the computational cost linearly increases with the number of trees and the gain in model performance levels out. Bagging also limits the interpretability. We can no longer visualise the fitted model with an intuitive graphical decision tree as done above.</p>
</div>
<div id="from-trees-to-a-forest" class="section level3 hasAnchor" number="11.2.3">
<h3><span class="header-section-number">11.2.3</span> From trees to a forest<a href="randomforest.html#from-trees-to-a-forest" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>While bagging reduces the variance in predictions, limits to predictive performance remain. This is linked to the fact that, although a certain degree of randomness is introduced by sub-sampling the training data for each tree, individual trees often remain relatively similar. This is particularly expressed if variations in the target variable are controlled primarily by variations in a small number of predictor variables. In this case, decision trees tend to be built by splits on the same variable, irrespective of which bootstrapped sample the individual tree is trained with.</p>
<p>Random Forest solves this problem by introducing an additional source of randomness: Only a subset of the predictor variables are considered at each split. This strongly reduces the similarity of individual trees (and also reduces computational costs) and leads to improved predictive performance.</p>
<p>The number of variables to consider at each split is a hyperparameter of the Random Forest algorithm, commonly named <span class="math inline">\(m_\text{try}\)</span>. In the example below, we use the implementation in the {ranger} package (wrapped with {caret}), where the respective model fitting function has a hyperparameter <code>mtry</code>. Common default values are <span class="math inline">\(m_\text{try} = P/3\)</span> for regression and <span class="math inline">\(m_\text{try} = \sqrt{P}\)</span> for classification, where <span class="math inline">\(P\)</span> is the number of predictors. Model complexity is controlled by the depth of the trees. Depending on the implementation of the Random Forest algorithm, this is governed not by explicitly specifying the tree depth, but by setting the number of observations in the leaf node. In the {ranger} package, the respective hyperparamter is <code>min.node.size</code>. The number of trees is another hyperparameter and affects predictions similarly as described above for bagging.</p>
<p>A great strength of Random Forest is, inherited by the characteristics of its underlying decision trees, its minimal requirement of data pre-processing, its capability of dealing with continuous and categorical variables, and its robustness to outliers. With the default choices of <span class="math inline">\(m_\text{try}\)</span>, Random Forest provides very good out-of-the-box performance. However, the hyperparameters of Random Forest have interactive effects and should be searched systematically.</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="randomforest.html#cb400-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data loading and cleaning</span></span>
<span id="cb400-2"><a href="randomforest.html#cb400-2" aria-hidden="true" tabindex="-1"></a>daily_fluxes <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;./data/FLX_CH-Dav_FLUXNET2015_FULLSET_DD_1997-2014_1-3.csv&quot;</span>) <span class="sc">|&gt;</span>  </span>
<span id="cb400-3"><a href="randomforest.html#cb400-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb400-4"><a href="randomforest.html#cb400-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># select only the variables we are interested in</span></span>
<span id="cb400-5"><a href="randomforest.html#cb400-5" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(TIMESTAMP,</span>
<span id="cb400-6"><a href="randomforest.html#cb400-6" aria-hidden="true" tabindex="-1"></a>                GPP_NT_VUT_REF,    <span class="co"># the target</span></span>
<span id="cb400-7"><a href="randomforest.html#cb400-7" aria-hidden="true" tabindex="-1"></a>                <span class="fu">ends_with</span>(<span class="st">&quot;_QC&quot;</span>),  <span class="co"># quality control info</span></span>
<span id="cb400-8"><a href="randomforest.html#cb400-8" aria-hidden="true" tabindex="-1"></a>                <span class="fu">ends_with</span>(<span class="st">&quot;_F&quot;</span>),   <span class="co"># includes all all meteorological covariates</span></span>
<span id="cb400-9"><a href="randomforest.html#cb400-9" aria-hidden="true" tabindex="-1"></a>                <span class="sc">-</span><span class="fu">contains</span>(<span class="st">&quot;JSB&quot;</span>)   <span class="co"># weird useless variable</span></span>
<span id="cb400-10"><a href="randomforest.html#cb400-10" aria-hidden="true" tabindex="-1"></a>                ) <span class="sc">|&gt;</span></span>
<span id="cb400-11"><a href="randomforest.html#cb400-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb400-12"><a href="randomforest.html#cb400-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># convert to a nice date object</span></span>
<span id="cb400-13"><a href="randomforest.html#cb400-13" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">TIMESTAMP =</span> <span class="fu">ymd</span>(TIMESTAMP)) <span class="sc">|&gt;</span></span>
<span id="cb400-14"><a href="randomforest.html#cb400-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb400-15"><a href="randomforest.html#cb400-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># set all -9999 to NA</span></span>
<span id="cb400-16"><a href="randomforest.html#cb400-16" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">na_if</span>(<span class="sc">-</span><span class="dv">9999</span>) <span class="sc">|&gt;</span></span>
<span id="cb400-17"><a href="randomforest.html#cb400-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb400-18"><a href="randomforest.html#cb400-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># retain only data based on &gt;=80% good-quality measurements</span></span>
<span id="cb400-19"><a href="randomforest.html#cb400-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># overwrite bad data with NA (not dropping rows)</span></span>
<span id="cb400-20"><a href="randomforest.html#cb400-20" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">GPP_NT_VUT_REF =</span> <span class="fu">ifelse</span>(NEE_VUT_REF_QC <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, GPP_NT_VUT_REF),</span>
<span id="cb400-21"><a href="randomforest.html#cb400-21" aria-hidden="true" tabindex="-1"></a>                <span class="at">TA_F           =</span> <span class="fu">ifelse</span>(TA_F_QC        <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, TA_F),</span>
<span id="cb400-22"><a href="randomforest.html#cb400-22" aria-hidden="true" tabindex="-1"></a>                <span class="at">SW_IN_F        =</span> <span class="fu">ifelse</span>(SW_IN_F_QC     <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, SW_IN_F),</span>
<span id="cb400-23"><a href="randomforest.html#cb400-23" aria-hidden="true" tabindex="-1"></a>                <span class="at">LW_IN_F        =</span> <span class="fu">ifelse</span>(LW_IN_F_QC     <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, LW_IN_F),</span>
<span id="cb400-24"><a href="randomforest.html#cb400-24" aria-hidden="true" tabindex="-1"></a>                <span class="at">VPD_F          =</span> <span class="fu">ifelse</span>(VPD_F_QC       <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, VPD_F),</span>
<span id="cb400-25"><a href="randomforest.html#cb400-25" aria-hidden="true" tabindex="-1"></a>                <span class="at">PA_F           =</span> <span class="fu">ifelse</span>(PA_F_QC        <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, PA_F),</span>
<span id="cb400-26"><a href="randomforest.html#cb400-26" aria-hidden="true" tabindex="-1"></a>                <span class="at">P_F            =</span> <span class="fu">ifelse</span>(P_F_QC         <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, P_F),</span>
<span id="cb400-27"><a href="randomforest.html#cb400-27" aria-hidden="true" tabindex="-1"></a>                <span class="at">WS_F           =</span> <span class="fu">ifelse</span>(WS_F_QC        <span class="sc">&lt;</span> <span class="fl">0.8</span>, <span class="cn">NA</span>, WS_F)) <span class="sc">|&gt;</span> </span>
<span id="cb400-28"><a href="randomforest.html#cb400-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb400-29"><a href="randomforest.html#cb400-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># drop QC variables (no longer needed)</span></span>
<span id="cb400-30"><a href="randomforest.html#cb400-30" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span><span class="fu">ends_with</span>(<span class="st">&quot;_QC&quot;</span>))</span></code></pre></div>
<pre><code>## Rows: 6574 Columns: 334
## ââ Column specification ââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
## Delimiter: &quot;,&quot;
## dbl (334): TIMESTAMP, TA_F_MDS, TA_F_MDS_QC, TA_F_MDS_NIGHT, TA_F_MDS_NIGHT_...
## 
## â¹ Use `spec()` to retrieve the full column specification for this data.
## â¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="randomforest.html#cb402-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data splitting</span></span>
<span id="cb402-2"><a href="randomforest.html#cb402-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># for reproducibility</span></span>
<span id="cb402-3"><a href="randomforest.html#cb402-3" aria-hidden="true" tabindex="-1"></a>split <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">initial_split</span>(daily_fluxes, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> <span class="st">&quot;VPD_F&quot;</span>)</span>
<span id="cb402-4"><a href="randomforest.html#cb402-4" aria-hidden="true" tabindex="-1"></a>daily_fluxes_train <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">training</span>(split)</span>
<span id="cb402-5"><a href="randomforest.html#cb402-5" aria-hidden="true" tabindex="-1"></a>daily_fluxes_test <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">testing</span>(split)</span>
<span id="cb402-6"><a href="randomforest.html#cb402-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-7"><a href="randomforest.html#cb402-7" aria-hidden="true" tabindex="-1"></a><span class="co"># The same model formulation is in the previous chapter</span></span>
<span id="cb402-8"><a href="randomforest.html#cb402-8" aria-hidden="true" tabindex="-1"></a>pp <span class="ot">&lt;-</span> recipes<span class="sc">::</span><span class="fu">recipe</span>(GPP_NT_VUT_REF <span class="sc">~</span> TA_F <span class="sc">+</span> SW_IN_F <span class="sc">+</span> LW_IN_F <span class="sc">+</span> VPD_F <span class="sc">+</span> P_F <span class="sc">+</span> WS_F, </span>
<span id="cb402-9"><a href="randomforest.html#cb402-9" aria-hidden="true" tabindex="-1"></a>                      <span class="at">data =</span> daily_fluxes_train) <span class="sc">|&gt;</span> </span>
<span id="cb402-10"><a href="randomforest.html#cb402-10" aria-hidden="true" tabindex="-1"></a>  recipes<span class="sc">::</span><span class="fu">step_center</span>(<span class="fu">all_numeric</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>()) <span class="sc">|&gt;</span></span>
<span id="cb402-11"><a href="randomforest.html#cb402-11" aria-hidden="true" tabindex="-1"></a>  recipes<span class="sc">::</span><span class="fu">step_scale</span>(<span class="fu">all_numeric</span>(), <span class="sc">-</span><span class="fu">all_outcomes</span>())</span>
<span id="cb402-12"><a href="randomforest.html#cb402-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb402-13"><a href="randomforest.html#cb402-13" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> caret<span class="sc">::</span><span class="fu">train</span>(</span>
<span id="cb402-14"><a href="randomforest.html#cb402-14" aria-hidden="true" tabindex="-1"></a>  pp, </span>
<span id="cb402-15"><a href="randomforest.html#cb402-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> daily_fluxes_train <span class="sc">%&gt;%</span> </span>
<span id="cb402-16"><a href="randomforest.html#cb402-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">drop_na</span>(), </span>
<span id="cb402-17"><a href="randomforest.html#cb402-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;ranger&quot;</span>,</span>
<span id="cb402-18"><a href="randomforest.html#cb402-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">metric =</span> <span class="st">&quot;RMSE&quot;</span>,</span>
<span id="cb402-19"><a href="randomforest.html#cb402-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">5</span>, <span class="at">savePredictions =</span> <span class="st">&quot;final&quot;</span>),</span>
<span id="cb402-20"><a href="randomforest.html#cb402-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>( <span class="at">.mtry =</span> <span class="fu">floor</span>(<span class="dv">6</span> <span class="sc">/</span> <span class="dv">3</span>),</span>
<span id="cb402-21"><a href="randomforest.html#cb402-21" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.min.node.size =</span> <span class="dv">5</span>,</span>
<span id="cb402-22"><a href="randomforest.html#cb402-22" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.splitrule =</span> <span class="st">&quot;variance&quot;</span>),</span>
<span id="cb402-23"><a href="randomforest.html#cb402-23" aria-hidden="true" tabindex="-1"></a>  <span class="co"># arguments specific to &quot;ranger&quot; method</span></span>
<span id="cb402-24"><a href="randomforest.html#cb402-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">replace =</span> <span class="cn">FALSE</span>,</span>
<span id="cb402-25"><a href="randomforest.html#cb402-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample.fraction =</span> <span class="fl">0.5</span>,</span>
<span id="cb402-26"><a href="randomforest.html#cb402-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">num.trees =</span> <span class="dv">2000</span>,          <span class="co"># high number ok since no hyperparam tuning</span></span>
<span id="cb402-27"><a href="randomforest.html#cb402-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">1982</span>                <span class="co"># for reproducibility</span></span>
<span id="cb402-28"><a href="randomforest.html#cb402-28" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;e1071&#39;
## 
## The following object is masked from &#39;package:rsample&#39;:
## 
##     permutations
## 
## The following object is masked from &#39;package:terra&#39;:
## 
##     interpolate</code></pre>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="randomforest.html#cb404-1" aria-hidden="true" tabindex="-1"></a><span class="co"># generic print</span></span>
<span id="cb404-2"><a href="randomforest.html#cb404-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(mod)</span></code></pre></div>
<pre><code>## Random Forest 
## 
## 1910 samples
##    8 predictor
## 
## Recipe steps: center, scale 
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 1528, 1528, 1529, 1527, 1528 
## Resampling results:
## 
##   RMSE      Rsquared   MAE     
##   1.411155  0.7047382  1.070285
## 
## Tuning parameter &#39;mtry&#39; was held constant at a value of 2
## Tuning
##  parameter &#39;splitrule&#39; was held constant at a value of variance
## 
## Tuning parameter &#39;min.node.size&#39; was held constant at a value of 5</code></pre>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="randomforest.html#cb406-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot model fit</span></span>
<span id="cb406-2"><a href="randomforest.html#cb406-2" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">&quot;R/eval_model.R&quot;</span>)</span>
<span id="cb406-3"><a href="randomforest.html#cb406-3" aria-hidden="true" tabindex="-1"></a><span class="fu">eval_model</span>(<span class="at">mod =</span> mod, <span class="at">df_train =</span> daily_fluxes_train, <span class="at">df_test =</span> daily_fluxes_test)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;
## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-210-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="exercises-8" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> Exercises<a href="randomforest.html#exercises-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="fitting-a-random-forest" class="section level3 unnumbered hasAnchor">
<h3>Fitting a Random Forest<a href="randomforest.html#fitting-a-random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Fit a random forest model to the flux data used in the examples of this chapter. Implement bagging 12 decision trees (<code>num.trees</code>), each with a maximum depth of 4 (<code>max.depth</code>). You can consult the respective arguments for the <code>"ranger"</code> method typing <code>?ranger</code>.</p>
<p>Repeat the fitting with 1000 decision trees and max depth of 4, then with 12 decision trees and a max depth of 6. Then, discuss the role that the number of decision trees and the maximum depth of a tree play in the bias-variance trade-off and in the computation time.</p>
</div>
<div id="hyperparameter-tuning" class="section level3 unnumbered hasAnchor">
<h3>Hyperparameter tuning<a href="randomforest.html#hyperparameter-tuning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In a previous tutorial, you learned how to tune the hyperparameter <span class="math inline">\(k\)</span> in a KNN by hand. Now you will do the hyperparameter tuning for a Random Forest model. The task gets more complicated because there are more hyperparameters in a random forest. The {caret} package allows to vary three hyperparameters:</p>
<ul>
<li><code>mtry</code>: The number of variables to consider to make decisions at each node, often taken as <span class="math inline">\(p/3\)</span> for regression, where <span class="math inline">\(p\)</span> is the number of predictors.</li>
<li><code>min.node.size</code>: The number of data points at the âbottomâ of each decision tree, i.e.Â the leaves.</li>
<li><code>splitrule</code>: The function applied to data in each branch of a tree, used for determining the goodness of a decision.</li>
</ul>
<p>Answer the following questions, giving a reason for your responses:</p>
<ol style="list-style-type: decimal">
<li><p>Check the help for the <code>ranger()</code> function and identify which values each of the three hyperparameters/arguments can take. Select a sensible range of values for each hyperparameter, that you will use in the hyperparameter search.</p></li>
<li><p>In the previous exercise, you have seen how the maximum tree depth regulates fit quality and overfitting. How does the minimum node size relate to tree depth? What happens at the edge cases, when <code>min.node.size = 1</code> and when <code>min.node.size = n</code> (<code>n</code> being the number of observations)? For the next questions, itâs not necessary to provide the <code>max.depth</code> argument to <code>train()</code> because <code>min.node.size</code> is already limiting the size of the trees in the random forests.</p></li>
<li><p><em>Greedy hyperparameter tuning</em>: Sequentially optimize the choice of each hyperparameter, one at a time and keeping the other two constant. Take the code from the tutorial as a starting point, and those hyperparameter values as an initial point for the search.
&gt; Tip: Keep the number of trees low, otherwise it takes too long to fit each random forest model.</p></li>
<li><p><em>Grid hyperparameter tuning</em>: Starting with the same range of values for each hyperparameter as before, look for the combination that leads to the best model performance among all combinations of hyperparameter values. This time, use the <code>expand.grid()</code> function to create a data.frame of hyperparameter value combinations. This grid will be passed to <code>train()</code> via the <code>tuneGrid</code> argument (see example in the tutorial). This will automatically do the hyperparameter search for you. Comment the output of <code>train()</code> and the results of the hyperparameter search.</p></li>
<li><p>Compare the results from the two hyperparameter tuning approaches. Do the optimal hyperparameters coincide? Are the corresponding RMSE estimates similar? What are the advantages and disadvantages of the greedy and the grid approaches?</p></li>
</ol>
</div>
<div id="model-performance" class="section level3 unnumbered hasAnchor">
<h3>Model performance<a href="randomforest.html#model-performance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>You have trained several random forest models. Evaluate the model performance on the best model (the one for the tuned hyperparameters) and on one of your worse models. If you compare the RMSE and <span class="math inline">\(R^2\)</span> on the training and the test set, does it show overfitting?</p>
</div>
<div id="xxx-solution" class="section level3 hasAnchor" number="11.3.1">
<h3><span class="header-section-number">11.3.1</span> XXX Solution<a href="randomforest.html#xxx-solution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As a starting point, letâs reuse the cleaned data and the hyperparameters from the example above.</p>
<p>Possible values for each hyperparameter:</p>
<ul>
<li><code>mtry</code> takes an integer between <span class="math inline">\(0\)</span> and <span class="math inline">\(p=6\)</span> (the number of predictors). A vector of possible values could be:</li>
</ul>
<pre><code>mtry &lt;- c(2, 3, 4)</code></pre>
<ul>
<li><code>min.node.size</code> is also an integer. You should keep in mind how many observations you have to train the model. For example, consider values:</li>
</ul>
<pre><code>min.node.size &lt;- c(2, 5, 10, 20)</code></pre>
<ul>
<li><code>splitrule</code> can take these values for a regression model: <code>"variance", "extratrees", "maxstat"</code> or <code>"beta"</code></li>
</ul>
<p><strong>Greedy hyperparameter search</strong></p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="randomforest.html#cb410-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define hyperparameter ranges</span></span>
<span id="cb410-2"><a href="randomforest.html#cb410-2" aria-hidden="true" tabindex="-1"></a>mtry_vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb410-3"><a href="randomforest.html#cb410-3" aria-hidden="true" tabindex="-1"></a>min.node.size_vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>)</span>
<span id="cb410-4"><a href="randomforest.html#cb410-4" aria-hidden="true" tabindex="-1"></a>splitrule_vec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;variance&quot;</span>, <span class="st">&quot;extratrees&quot;</span>, <span class="st">&quot;maxstat&quot;</span>, <span class="st">&quot;beta&quot;</span>)</span>
<span id="cb410-5"><a href="randomforest.html#cb410-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb410-6"><a href="randomforest.html#cb410-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define function to train model, given parameter values</span></span>
<span id="cb410-7"><a href="randomforest.html#cb410-7" aria-hidden="true" tabindex="-1"></a><span class="cf">function</span>(mtry, min.node.size, splitrule){</span>
<span id="cb410-8"><a href="randomforest.html#cb410-8" aria-hidden="true" tabindex="-1"></a>  mod <span class="ot">&lt;-</span> caret<span class="sc">::</span><span class="fu">train</span>(</span>
<span id="cb410-9"><a href="randomforest.html#cb410-9" aria-hidden="true" tabindex="-1"></a>    pp, </span>
<span id="cb410-10"><a href="randomforest.html#cb410-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> daily_fluxes_train <span class="sc">%&gt;%</span> </span>
<span id="cb410-11"><a href="randomforest.html#cb410-11" aria-hidden="true" tabindex="-1"></a>      <span class="fu">drop_na</span>(), </span>
<span id="cb410-12"><a href="randomforest.html#cb410-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">method =</span> <span class="st">&quot;ranger&quot;</span>,</span>
<span id="cb410-13"><a href="randomforest.html#cb410-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">5</span>, <span class="at">savePredictions =</span> <span class="st">&quot;final&quot;</span>),</span>
<span id="cb410-14"><a href="randomforest.html#cb410-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>( <span class="at">.mtry =</span> mtry, <span class="co"># vary hyperparameter</span></span>
<span id="cb410-15"><a href="randomforest.html#cb410-15" aria-hidden="true" tabindex="-1"></a>                            <span class="at">.min.node.size =</span> min.node.size,</span>
<span id="cb410-16"><a href="randomforest.html#cb410-16" aria-hidden="true" tabindex="-1"></a>                            <span class="at">.splitrule =</span> splitrule),</span>
<span id="cb410-17"><a href="randomforest.html#cb410-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">metric =</span> <span class="st">&quot;RMSE&quot;</span>,</span>
<span id="cb410-18"><a href="randomforest.html#cb410-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">replace =</span> <span class="cn">FALSE</span>,</span>
<span id="cb410-19"><a href="randomforest.html#cb410-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample.fraction =</span> <span class="fl">0.5</span>,</span>
<span id="cb410-20"><a href="randomforest.html#cb410-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">num.trees =</span> <span class="dv">2000</span>,           <span class="co"># reduce number for hyperparameter tuning</span></span>
<span id="cb410-21"><a href="randomforest.html#cb410-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">seed =</span> <span class="dv">1982</span>                 <span class="co"># for reproducibility</span></span>
<span id="cb410-22"><a href="randomforest.html#cb410-22" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb410-23"><a href="randomforest.html#cb410-23" aria-hidden="true" tabindex="-1"></a>  mod<span class="sc">$</span>results<span class="sc">$</span>RMSE              <span class="co"># return RMSE </span></span>
<span id="cb410-24"><a href="randomforest.html#cb410-24" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## function(mtry, min.node.size, splitrule){
##   mod &lt;- caret::train(
##     pp, 
##     data = daily_fluxes_train %&gt;% 
##       drop_na(), 
##     method = &quot;ranger&quot;,
##     trControl = trainControl(method = &quot;cv&quot;, number = 5, savePredictions = &quot;final&quot;),
##     tuneGrid = expand.grid( .mtry = mtry, # vary hyperparameter
##                             .min.node.size = min.node.size,
##                             .splitrule = splitrule),
##     metric = &quot;RMSE&quot;,
##     replace = FALSE,
##     sample.fraction = 0.5,
##     num.trees = 2000,           # reduce number for hyperparameter tuning
##     seed = 1982                 # for reproducibility
##   )
##   mod$results$RMSE              # return RMSE 
## }</code></pre>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="randomforest.html#cb412-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(mtry <span class="cf">in</span> mtry_vec){</span>
<span id="cb412-2"><a href="randomforest.html#cb412-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb412-3"><a href="randomforest.html#cb412-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Now, using the implicit hyperparameter tuning in <code>train()</code>:</p>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="randomforest.html#cb413-1" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> caret<span class="sc">::</span><span class="fu">train</span>(</span>
<span id="cb413-2"><a href="randomforest.html#cb413-2" aria-hidden="true" tabindex="-1"></a>  pp, </span>
<span id="cb413-3"><a href="randomforest.html#cb413-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> daily_fluxes_train <span class="sc">%&gt;%</span> </span>
<span id="cb413-4"><a href="randomforest.html#cb413-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">drop_na</span>(), </span>
<span id="cb413-5"><a href="randomforest.html#cb413-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;ranger&quot;</span>,</span>
<span id="cb413-6"><a href="randomforest.html#cb413-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">5</span>, <span class="at">savePredictions =</span> <span class="st">&quot;final&quot;</span>),</span>
<span id="cb413-7"><a href="randomforest.html#cb413-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>( <span class="at">.mtry =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>),</span>
<span id="cb413-8"><a href="randomforest.html#cb413-8" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.min.node.size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>),</span>
<span id="cb413-9"><a href="randomforest.html#cb413-9" aria-hidden="true" tabindex="-1"></a>                          <span class="at">.splitrule =</span> <span class="fu">c</span>(<span class="st">&quot;variance&quot;</span>, <span class="st">&quot;maxstat&quot;</span>)),</span>
<span id="cb413-10"><a href="randomforest.html#cb413-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">metric =</span> <span class="st">&quot;RMSE&quot;</span>,</span>
<span id="cb413-11"><a href="randomforest.html#cb413-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">replace =</span> <span class="cn">FALSE</span>,</span>
<span id="cb413-12"><a href="randomforest.html#cb413-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample.fraction =</span> <span class="fl">0.5</span>,</span>
<span id="cb413-13"><a href="randomforest.html#cb413-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">num.trees =</span> <span class="dv">200</span>,           <span class="co"># reduce number for hyperparameter tuning</span></span>
<span id="cb413-14"><a href="randomforest.html#cb413-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> <span class="dv">1982</span>                <span class="co"># for reproducibility</span></span>
<span id="cb413-15"><a href="randomforest.html#cb413-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb413-16"><a href="randomforest.html#cb413-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb413-17"><a href="randomforest.html#cb413-17" aria-hidden="true" tabindex="-1"></a>mod<span class="sc">$</span>bestTune                 <span class="co"># best tuned parameters</span></span></code></pre></div>
<pre><code>##    mtry splitrule min.node.size
## 15    4  variance            10</code></pre>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="randomforest.html#cb415-1" aria-hidden="true" tabindex="-1"></a>mod<span class="sc">$</span>results                  <span class="co"># performance metrics for all hyperparameters</span></span></code></pre></div>
<pre><code>##    mtry min.node.size splitrule     RMSE  Rsquared      MAE     RMSESD
## 1     2             5  variance 1.422200 0.6987716 1.081181 0.08895616
## 3     2            10  variance 1.426829 0.6970420 1.084085 0.09205539
## 5     2            20  variance 1.430377 0.6960730 1.088748 0.09626036
## 2     2             5   maxstat 1.452990 0.6892293 1.108527 0.09221732
## 4     2            10   maxstat 1.454473 0.6886987 1.109638 0.09232731
## 6     2            20   maxstat 1.458050 0.6875142 1.112393 0.09358934
## 7     3             5  variance 1.420918 0.6990189 1.077218 0.08954330
## 9     3            10  variance 1.418337 0.7002084 1.077153 0.08853160
## 11    3            20  variance 1.423339 0.6981565 1.082833 0.08977861
## 8     3             5   maxstat 1.437825 0.6929920 1.092282 0.08694014
## 10    3            10   maxstat 1.438679 0.6926356 1.093050 0.08729321
## 12    3            20   maxstat 1.442043 0.6913524 1.096902 0.08825508
## 13    4             5  variance 1.419620 0.6997016 1.077443 0.07949985
## 15    4            10  variance 1.416170 0.7010820 1.076972 0.08208228
## 17    4            20  variance 1.422309 0.6984764 1.081167 0.08649232
## 14    4             5   maxstat 1.435328 0.6933534 1.089247 0.08589809
## 16    4            10   maxstat 1.435721 0.6931931 1.089621 0.08617305
## 18    4            20   maxstat 1.439081 0.6918436 1.092500 0.08655005
##    RsquaredSD      MAESD
## 1  0.02263056 0.05149702
## 3  0.02243498 0.05083169
## 5  0.02453486 0.05282167
## 2  0.02214342 0.05362546
## 4  0.02227651 0.05297754
## 6  0.02293964 0.05305311
## 7  0.02482813 0.05261510
## 9  0.02383288 0.05244123
## 11 0.02339664 0.05034847
## 8  0.02166101 0.05220413
## 10 0.02197110 0.05250078
## 12 0.02233486 0.05302330
## 13 0.02045071 0.05063402
## 15 0.02126535 0.04880612
## 17 0.02259025 0.05051418
## 14 0.02239920 0.05221632
## 16 0.02251599 0.05254402
## 18 0.02251706 0.05269749</code></pre>
<p>The best model is the one resulting from hyperparameters</p>

</div>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="supervisedmlii.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="solutions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
